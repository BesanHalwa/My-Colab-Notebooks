{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo Step-by-Step.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "URGjHRd_pxRy",
        "colab_type": "code",
        "outputId": "23505aa6-5553-4e3d-efc6-a6f147ca3ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tby4AnlwqHF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS0FcIp2qHRL",
        "colab_type": "code",
        "outputId": "390d21f1-f311-4e4a-ac31-3ed700572731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/project_data/keras-yolo2-master/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/project_data/keras-yolo2-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh52HH9yqHPT",
        "colab_type": "code",
        "outputId": "ab0af3a5-e437-4333-95a5-2cd332d2427d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mAnnotations\u001b[0m/   frontend.py     predict.py        train.py\r\n",
            "backend.py     gen_anchors.py  preprocessing.py  utils.py\r\n",
            "config.json    \u001b[01;34mimages\u001b[0m/         \u001b[01;34m__pycache__\u001b[0m/      Yolo Step-by-Step.ipynb\r\n",
            "\u001b[01;34mexamples\u001b[0m/      \u001b[01;34mJPEGImages\u001b[0m/     README.md         yolov2.weights\r\n",
            "\u001b[01;34mexperimental\u001b[0m/  LICENSE         requirements.txt\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eSGMl6BqHMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkjrk1uDqHKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iY1MUtWqHJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiDe_WdjpxR5",
        "colab_type": "text"
      },
      "source": [
        "**Outline of Steps**\n",
        "    + Initialization\n",
        "        + Download COCO detection data from http://cocodataset.org/#download\n",
        "            + http://images.cocodataset.org/zips/train2014.zip <= train images\n",
        "            + http://images.cocodataset.org/zips/val2014.zip <= validation images\n",
        "            + http://images.cocodataset.org/annotations/annotations_trainval2014.zip <= train and validation annotations\n",
        "        + Run this script to convert annotations in COCO format to VOC format\n",
        "            + https://gist.github.com/chicham/6ed3842d0d2014987186#file-coco2pascal-py\n",
        "        + Download pre-trained weights from https://pjreddie.com/darknet/yolo/\n",
        "            + https://pjreddie.com/media/files/yolo.weights\n",
        "        + Specify the directory of train annotations (train_annot_folder) and train images (train_image_folder)\n",
        "        + Specify the directory of validation annotations (valid_annot_folder) and validation images (valid_image_folder)\n",
        "        + Specity the path of pre-trained weights by setting variable *wt_path*\n",
        "    + Construct equivalent network in Keras\n",
        "        + Network arch from https://github.com/pjreddie/darknet/blob/master/cfg/yolo-voc.cfg\n",
        "    + Load the pretrained weights\n",
        "    + Perform training \n",
        "    + Perform detection on an image with newly trained weights\n",
        "    + Perform detection on an video with newly trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDUGdAPlpxR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5CfZQJBpxSE",
        "colab_type": "text"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW8WbA5IpxSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.layers.merge import concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import imgaug as ia\n",
        "from tqdm import tqdm\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os, cv2\n",
        "from preprocessing import parse_annotation, BatchGenerator\n",
        "from utils import WeightReader, decode_netout, draw_boxes\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-viEeuiqel-",
        "colab_type": "code",
        "outputId": "b7898ac8-2523-4560-e21f-61adb5397b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e6/19dfaff08fcbee7f3453e5b537e65a8364f1945f921a36d08be1e2ff3475/tqdm-4.24.0-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.24.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L2SiZzLpxSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "IMAGE_H, IMAGE_W = 416, 416\n",
        "GRID_H,  GRID_W  = 13 , 13\n",
        "BOX              = 5\n",
        "CLASS            = len(LABELS)\n",
        "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
        "OBJ_THRESHOLD    = 0.3#0.5\n",
        "NMS_THRESHOLD    = 0.3#0.45\n",
        "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
        "\n",
        "NO_OBJECT_SCALE  = 1.0\n",
        "OBJECT_SCALE     = 5.0\n",
        "COORD_SCALE      = 1.0\n",
        "CLASS_SCALE      = 1.0\n",
        "\n",
        "BATCH_SIZE       = 16\n",
        "WARM_UP_BATCHES  = 0\n",
        "TRUE_BOX_BUFFER  = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWFKULn0pxSO",
        "colab_type": "code",
        "outputId": "a3f0d2fc-a7c8-40f7-9146-67419301734e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "CLASS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cToGW6nEpxSS",
        "colab_type": "code",
        "outputId": "9da5cb62-c992-4fcd-8303-30ba2881c88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/project_data/keras-yolo2-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p7EVVFTpxSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wt_path = 'yolov2.weights'                      \n",
        "train_image_folder = 'JPEGImages/'\n",
        "train_annot_folder = 'Annotations/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUQcRO7CpxSW",
        "colab_type": "text"
      },
      "source": [
        "# Construct the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RRGbdHzpxSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPOy7cfopxSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
        "\n",
        "# Layer 1\n",
        "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "x = BatchNormalization(name='norm_1')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 2\n",
        "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_2')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 3\n",
        "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_3')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 4\n",
        "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_4')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 5\n",
        "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_5')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 6\n",
        "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_6')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 7\n",
        "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_7')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 8\n",
        "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_8')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 9\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_9')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 10\n",
        "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_10')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 11\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_11')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 12\n",
        "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_12')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 13\n",
        "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_13')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "skip_connection = x\n",
        "\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "# Layer 14\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_14')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 15\n",
        "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_15')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 16\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_16')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 17\n",
        "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_17')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 18\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_18')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 19\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_19')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 20\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_20')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 21\n",
        "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
        "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\n",
        "x = concatenate([skip_connection, x])\n",
        "\n",
        "# Layer 22\n",
        "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
        "x = BatchNormalization(name='norm_22')(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Layer 23\n",
        "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
        "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
        "\n",
        "# small hack to allow true_boxes to be registered when Keras build the model \n",
        "# for more information: https://github.com/fchollet/keras/issues/2790\n",
        "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
        "\n",
        "model = Model([input_image, true_boxes], output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oywjDvL6pxSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from IPython.display import SVG\n",
        "# from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "# SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfQWeF0mpxSd",
        "colab_type": "text"
      },
      "source": [
        "# Load pretrained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBavv-vZpxSe",
        "colab_type": "text"
      },
      "source": [
        "**Load the weights originally provided by YOLO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7q7eeHJpxSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_reader = WeightReader(wt_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcJVwb5YpxSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_reader.reset()\n",
        "nb_conv = 23\n",
        "\n",
        "for i in range(1, nb_conv+1):\n",
        "    conv_layer = model.get_layer('conv_' + str(i))\n",
        "    \n",
        "    if i < nb_conv:\n",
        "        norm_layer = model.get_layer('norm_' + str(i))\n",
        "        \n",
        "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "        beta  = weight_reader.read_bytes(size)\n",
        "        gamma = weight_reader.read_bytes(size)\n",
        "        mean  = weight_reader.read_bytes(size)\n",
        "        var   = weight_reader.read_bytes(size)\n",
        "\n",
        "        weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
        "        \n",
        "    if len(conv_layer.get_weights()) > 1:\n",
        "        bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "        kernel = kernel.transpose([2,3,1,0])\n",
        "        conv_layer.set_weights([kernel, bias])\n",
        "    else:\n",
        "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "        kernel = kernel.transpose([2,3,1,0])\n",
        "        conv_layer.set_weights([kernel])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8oJkcropxSh",
        "colab_type": "text"
      },
      "source": [
        "**Randomize weights of the last layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y-zunFapxSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer   = model.layers[-4] # the last convolutional layer\n",
        "weights = layer.get_weights()\n",
        "\n",
        "new_kernel = np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W)\n",
        "new_bias   = np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)\n",
        "\n",
        "layer.set_weights([new_kernel, new_bias])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1KwodzfpxSj",
        "colab_type": "text"
      },
      "source": [
        "# Perform training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CRv19fppxSj",
        "colab_type": "text"
      },
      "source": [
        "**Loss function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxEyQ9m3pxSk",
        "colab_type": "text"
      },
      "source": [
        "$$\\begin{multline}\n",
        "\\lambda_\\textbf{coord}\n",
        "\\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "     L_{ij}^{\\text{obj}}\n",
        "            \\left[\n",
        "            \\left(\n",
        "                x_i - \\hat{x}_i\n",
        "            \\right)^2 +\n",
        "            \\left(\n",
        "                y_i - \\hat{y}_i\n",
        "            \\right)^2\n",
        "            \\right]\n",
        "\\\\\n",
        "+ \\lambda_\\textbf{coord} \n",
        "\\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "         L_{ij}^{\\text{obj}}\n",
        "         \\left[\n",
        "        \\left(\n",
        "            \\sqrt{w_i} - \\sqrt{\\hat{w}_i}\n",
        "        \\right)^2 +\n",
        "        \\left(\n",
        "            \\sqrt{h_i} - \\sqrt{\\hat{h}_i}\n",
        "        \\right)^2\n",
        "        \\right]\n",
        "\\\\\n",
        "+ \\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "        L_{ij}^{\\text{obj}}\n",
        "        \\left(\n",
        "            C_i - \\hat{C}_i\n",
        "        \\right)^2\n",
        "\\\\\n",
        "+ \\lambda_\\textrm{noobj}\n",
        "\\sum_{i = 0}^{S^2}\n",
        "    \\sum_{j = 0}^{B}\n",
        "    L_{ij}^{\\text{noobj}}\n",
        "        \\left(\n",
        "            C_i - \\hat{C}_i\n",
        "        \\right)^2\n",
        "\\\\\n",
        "+ \\sum_{i = 0}^{S^2}\n",
        "L_i^{\\text{obj}}\n",
        "    \\sum_{c \\in \\textrm{classes}}\n",
        "        \\left(\n",
        "            p_i(c) - \\hat{p}_i(c)\n",
        "        \\right)^2\n",
        "\\end{multline}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dl-bRkqpxSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    mask_shape = tf.shape(y_true)[:4]\n",
        "    \n",
        "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
        "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\n",
        "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
        "    \n",
        "    coord_mask = tf.zeros(mask_shape)\n",
        "    conf_mask  = tf.zeros(mask_shape)\n",
        "    class_mask = tf.zeros(mask_shape)\n",
        "    \n",
        "    seen = tf.Variable(0.)\n",
        "    total_recall = tf.Variable(0.)\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust prediction\n",
        "    \"\"\"\n",
        "    ### adjust x and y      \n",
        "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "    \n",
        "    ### adjust w and h\n",
        "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
        "    \n",
        "    ### adjust confidence\n",
        "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    pred_box_class = y_pred[..., 5:]\n",
        "    \n",
        "    \"\"\"\n",
        "    Adjust ground truth\n",
        "    \"\"\"\n",
        "    ### adjust x and y\n",
        "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
        "    \n",
        "    ### adjust w and h\n",
        "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
        "    \n",
        "    ### adjust confidence\n",
        "    true_wh_half = true_box_wh / 2.\n",
        "    true_mins    = true_box_xy - true_wh_half\n",
        "    true_maxes   = true_box_xy + true_wh_half\n",
        "    \n",
        "    pred_wh_half = pred_box_wh / 2.\n",
        "    pred_mins    = pred_box_xy - pred_wh_half\n",
        "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "    \n",
        "    true_box_conf = iou_scores * y_true[..., 4]\n",
        "    \n",
        "    ### adjust class probabilities\n",
        "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "    \n",
        "    \"\"\"\n",
        "    Determine the masks\n",
        "    \"\"\"\n",
        "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
        "    \n",
        "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
        "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "    true_xy = true_boxes[..., 0:2]\n",
        "    true_wh = true_boxes[..., 2:4]\n",
        "    \n",
        "    true_wh_half = true_wh / 2.\n",
        "    true_mins    = true_xy - true_wh_half\n",
        "    true_maxes   = true_xy + true_wh_half\n",
        "    \n",
        "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "    \n",
        "    pred_wh_half = pred_wh / 2.\n",
        "    pred_mins    = pred_xy - pred_wh_half\n",
        "    pred_maxes   = pred_xy + pred_wh_half    \n",
        "    \n",
        "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    \n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
        "    \n",
        "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
        "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
        "    \n",
        "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
        "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
        "    \n",
        "    \"\"\"\n",
        "    Warm-up training\n",
        "    \"\"\"\n",
        "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
        "    seen = tf.assign_add(seen, 1.)\n",
        "    \n",
        "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
        "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
        "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
        "                                   tf.ones_like(coord_mask)],\n",
        "                          lambda: [true_box_xy, \n",
        "                                   true_box_wh,\n",
        "                                   coord_mask])\n",
        "    \n",
        "    \"\"\"\n",
        "    Finalize the loss\n",
        "    \"\"\"\n",
        "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
        "    \n",
        "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
        "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
        "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
        "    \n",
        "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
        "    \n",
        "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
        "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
        "\n",
        "    \"\"\"\n",
        "    Debugging code\n",
        "    \"\"\"    \n",
        "    current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "    total_recall = tf.assign_add(total_recall, current_recall) \n",
        "\n",
        "    loss = tf.Print(loss, [tf.zeros((1))], message='Dummy Line \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
        "    loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep7DjzAipxSl",
        "colab_type": "text"
      },
      "source": [
        "**Parse the annotations to construct train generator and validation generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOua0qYPpxSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_config = {\n",
        "    'IMAGE_H'         : IMAGE_H, \n",
        "    'IMAGE_W'         : IMAGE_W,\n",
        "    'GRID_H'          : GRID_H,  \n",
        "    'GRID_W'          : GRID_W,\n",
        "    'BOX'             : BOX,\n",
        "    'LABELS'          : LABELS,\n",
        "    'CLASS'           : len(LABELS),\n",
        "    'ANCHORS'         : ANCHORS,\n",
        "    'BATCH_SIZE'      : BATCH_SIZE,\n",
        "    'TRUE_BOX_BUFFER' : 50,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMbuJ0R4pxSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(image):\n",
        "    return image / 255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zM0msYdpxSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs, seen_train_labels = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)\n",
        "### write parsed annotations to pickle for fast retrieval next time\n",
        "#with open('train_imgs', 'wb') as fp:\n",
        "#    pickle.dump(train_imgs, fp)\n",
        "\n",
        "### read saved pickle of parsed annotations\n",
        "#with open ('train_imgs', 'rb') as fp:\n",
        "#    train_imgs = pickle.load(fp)\n",
        "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
        "\n",
        "# valid_imgs, seen_valid_labels = parse_annotation(valid_annot_folder, valid_image_folder, labels=LABELS)\n",
        "# ### write parsed annotations to pickle for fast retrieval next time\n",
        "# #with open('valid_imgs', 'wb') as fp:\n",
        "# #    pickle.dump(valid_imgs, fp)\n",
        "\n",
        "# ### read saved pickle of parsed annotations\n",
        "# #with open ('valid_imgs', 'rb') as fp:\n",
        "# #    valid_imgs = pickle.load(fp)\n",
        "# valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzHM1MWDpxSo",
        "colab_type": "code",
        "outputId": "8bae847d-f6c1-4cd5-ef11-95e23265d460",
        "colab": {}
      },
      "source": [
        "# len(train_imgs)\n",
        "generator= train_batch\n",
        "generator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<preprocessing.BatchGenerator at 0x13ccdcfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3LE4F4XpxSq",
        "colab_type": "text"
      },
      "source": [
        "**Setup a few callbacks and start the training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8agw9QBZpxSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', \n",
        "                           min_delta=0.001, \n",
        "                           patience=3, \n",
        "                           mode='min', \n",
        "                           verbose=1)\n",
        "\n",
        "checkpoint = ModelCheckpoint('weights_coco.h5', \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1, \n",
        "                             save_best_only=True, \n",
        "                             mode='min', \n",
        "                             period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftQgOoNvpxSs",
        "colab_type": "code",
        "outputId": "eb59e88c-cdf5-4565-ccac-366cd11a3a0c",
        "colab": {}
      },
      "source": [
        "# tb_counter  = len([log for log in os.listdir(os.path.expanduser('~/logs/')) if 'coco_' in log]) + 1\n",
        "# tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/') + 'coco_' + '_' + str(tb_counter), \n",
        "#                           histogram_freq=0, \n",
        "#                           write_graph=True, \n",
        "#                           write_images=False)\n",
        "\n",
        "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
        "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(loss=custom_loss, optimizer=optimizer,metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(generator        = train_batch, \n",
        "                    steps_per_epoch  = len(train_batch), \n",
        "                    epochs           = 100, \n",
        "                    verbose          = 1,\n",
        "                    callbacks        = [early_stop, checkpoint], \n",
        "                    max_queue_size   = 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  8/990 [..............................] - ETA: 10:26:30 - loss: 6.7858 - acc: 0.0132"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-8561d794a803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mverbose\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mcallbacks\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     max_queue_size   = 3)\n\u001b[0m",
            "\u001b[0;32m~/Desktop/notebook/env/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/notebook/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/notebook/env/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/notebook/env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/notebook/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/notebook/env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/notebook/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "who1eJPfpxSu",
        "colab_type": "text"
      },
      "source": [
        "# Perform detection on image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXXOb1A7pxSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"weights_coco.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAS5FOAvpxSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread('images/giraffe.jpg')\n",
        "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "input_image = cv2.resize(image, (416, 416))\n",
        "input_image = input_image / 255.\n",
        "input_image = input_image[:,:,::-1]\n",
        "input_image = np.expand_dims(input_image, 0)\n",
        "\n",
        "netout = model.predict([input_image, dummy_array])\n",
        "\n",
        "boxes = decode_netout(netout[0], \n",
        "                      obj_threshold=OBJ_THRESHOLD,\n",
        "                      nms_threshold=NMS_THRESHOLD,\n",
        "                      anchors=ANCHORS, \n",
        "                      nb_class=CLASS)\n",
        "            \n",
        "image = draw_boxes(image, boxes, labels=LABELS)\n",
        "\n",
        "plt.imshow(image[:,:,::-1]); plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDFGtrXpxSx",
        "colab_type": "text"
      },
      "source": [
        "# Perform detection on video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hCf-GqkpxSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"weights_coco.h5\")\n",
        "\n",
        "dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXbf2iIxpxSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "video_inp = '../basic-yolo-keras/images/phnom_penh.mp4'\n",
        "video_out = '../basic-yolo-keras/images/phnom_penh_bbox.mp4'\n",
        "\n",
        "video_reader = cv2.VideoCapture(video_inp)\n",
        "\n",
        "nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\n",
        "video_writer = cv2.VideoWriter(video_out,\n",
        "                               cv2.VideoWriter_fourcc(*'XVID'), \n",
        "                               50.0, \n",
        "                               (frame_w, frame_h))\n",
        "\n",
        "for i in tqdm(range(nb_frames)):\n",
        "    ret, image = video_reader.read()\n",
        "    \n",
        "    input_image = cv2.resize(image, (416, 416))\n",
        "    input_image = input_image / 255.\n",
        "    input_image = input_image[:,:,::-1]\n",
        "    input_image = np.expand_dims(input_image, 0)\n",
        "\n",
        "    netout = model.predict([input_image, dummy_array])\n",
        "\n",
        "    boxes = decode_netout(netout[0], \n",
        "                          obj_threshold=0.3,\n",
        "                          nms_threshold=NMS_THRESHOLD,\n",
        "                          anchors=ANCHORS, \n",
        "                          nb_class=CLASS)\n",
        "    image = draw_boxes(image, boxes, labels=LABELS)\n",
        "\n",
        "    video_writer.write(np.uint8(image))\n",
        "    \n",
        "video_reader.release()\n",
        "video_writer.release()  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}