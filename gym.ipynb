{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gym.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjKFpZ8577nA",
        "colab_type": "code",
        "outputId": "26065f87-07f7-435c-8495-0748f952ab3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install gym"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gym\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/50/ed4a03d2be47ffd043be2ee514f329ce45d98a30fe2d1b9c61dea5a9d861/gym-0.10.5.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.5)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Collecting pyglet>=1.2.0 (from gym)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.0MB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.8.24)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/cb/14/71/f4ab006b1e6ff75c2b54985c2f98d0644fffe9c1dddc670925\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, gym\n",
            "Successfully installed gym-0.10.5 pyglet-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk-rBYU98ZS_",
        "colab_type": "code",
        "outputId": "60a55317-3ff0-4466-e353-2a0006ff7115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2876
        }
      },
      "source": [
        "!apt-get install python-opengl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2\n",
            "  libdrm-radeon1 libdrm2 libelf1 libgl1-mesa-dri libgl1-mesa-glx libglapi-mesa\n",
            "  libglu1-mesa libllvm5.0 libpciaccess0 libsensors4 libtxc-dxtn-s2tc\n",
            "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
            "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxxf86vm1\n",
            "Suggested packages:\n",
            "  pciutils lm-sensors python-numpy libgle3\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2\n",
            "  libdrm-radeon1 libdrm2 libelf1 libgl1-mesa-dri libgl1-mesa-glx libglapi-mesa\n",
            "  libglu1-mesa libllvm5.0 libpciaccess0 libsensors4 libtxc-dxtn-s2tc\n",
            "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
            "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxxf86vm1\n",
            "  python-opengl\n",
            "0 upgraded, 28 newly installed, 0 to remove and 0 not upgraded.\n",
            "Need to get 20.7 MB of archives.\n",
            "After this operation, 194 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu artful/main amd64 libxshmfence1 amd64 1.2-1 [5,042 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu artful/main amd64 libxxf86vm1 amd64 1:1.1.4-1 [10.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu artful/main amd64 libelf1 amd64 0.170-0.1 [44.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-common all 2.4.83-1 [4,938 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm2 amd64 2.4.83-1 [30.6 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libglapi-mesa amd64 17.2.8-0ubuntu0~17.10.1 [22.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu artful/main amd64 libx11-xcb1 amd64 2:1.6.4-3 [9,626 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-dri2-0 amd64 1.12-1ubuntu1 [6,838 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-dri3-0 amd64 1.12-1ubuntu1 [5,156 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-glx0 amd64 1.12-1ubuntu1 [22.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-present0 amd64 1.12-1ubuntu1 [5,436 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu artful/main amd64 libxcb-sync1 amd64 1.12-1ubuntu1 [8,746 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu artful/main amd64 libxdamage1 amd64 1:1.1.4-3 [6,934 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu artful/main amd64 libxfixes3 amd64 1:5.0.3-1 [10.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-amdgpu1 amd64 2.4.83-1 [18.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu artful/main amd64 libpciaccess0 amd64 0.13.4-1ubuntu1 [17.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-intel1 amd64 2.4.83-1 [59.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-nouveau2 amd64 2.4.83-1 [16.4 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu artful/main amd64 libdrm-radeon1 amd64 2.4.83-1 [21.6 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu artful/main amd64 libllvm5.0 amd64 1:5.0-3 [13.7 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu artful/main amd64 libsensors4 amd64 1:3.4.0-4 [28.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libgl1-mesa-dri amd64 17.2.8-0ubuntu0~17.10.1 [5,707 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu artful-updates/main amd64 libgl1-mesa-glx amd64 17.2.8-0ubuntu0~17.10.1 [130 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu artful/main amd64 libxi6 amd64 2:1.7.9-1 [29.2 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu artful/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu artful/main amd64 libglu1-mesa amd64 9.0.0-2.1build1 [168 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu artful/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu artful/main amd64 libtxc-dxtn-s2tc amd64 1.0+git20151227-2 [48.4 kB]\n",
            "Fetched 20.7 MB in 4s (4,306 kB/s)\n",
            "Selecting previously unselected package libxshmfence1:amd64.\n",
            "(Reading database ... 18408 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxshmfence1_1.2-1_amd64.deb ...\n",
            "Unpacking libxshmfence1:amd64 (1.2-1) ...\n",
            "Selecting previously unselected package libxxf86vm1:amd64.\n",
            "Preparing to unpack .../01-libxxf86vm1_1%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
            "Selecting previously unselected package libelf1:amd64.\n",
            "Preparing to unpack .../02-libelf1_0.170-0.1_amd64.deb ...\n",
            "Unpacking libelf1:amd64 (0.170-0.1) ...\n",
            "Selecting previously unselected package libdrm-common.\n",
            "Preparing to unpack .../03-libdrm-common_2.4.83-1_all.deb ...\n",
            "Unpacking libdrm-common (2.4.83-1) ...\n",
            "Selecting previously unselected package libdrm2:amd64.\n",
            "Preparing to unpack .../04-libdrm2_2.4.83-1_amd64.deb ...\n",
            "Unpacking libdrm2:amd64 (2.4.83-1) ...\n",
            "Selecting previously unselected package libglapi-mesa:amd64.\n",
            "Preparing to unpack .../05-libglapi-mesa_17.2.8-0ubuntu0~17.10.1_amd64.deb ...\n",
            "Unpacking libglapi-mesa:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n",
            "Selecting previously unselected package libx11-xcb1:amd64.\n",
            "Preparing to unpack .../06-libx11-xcb1_2%3a1.6.4-3_amd64.deb ...\n",
            "Unpacking libx11-xcb1:amd64 (2:1.6.4-3) ...\n",
            "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
            "Preparing to unpack .../07-libxcb-dri2-0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-dri2-0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
            "Preparing to unpack .../08-libxcb-dri3-0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-dri3-0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-glx0:amd64.\n",
            "Preparing to unpack .../09-libxcb-glx0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-glx0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-present0:amd64.\n",
            "Preparing to unpack .../10-libxcb-present0_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-present0:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxcb-sync1:amd64.\n",
            "Preparing to unpack .../11-libxcb-sync1_1.12-1ubuntu1_amd64.deb ...\n",
            "Unpacking libxcb-sync1:amd64 (1.12-1ubuntu1) ...\n",
            "Selecting previously unselected package libxdamage1:amd64.\n",
            "Preparing to unpack .../12-libxdamage1_1%3a1.1.4-3_amd64.deb ...\n",
            "Unpacking libxdamage1:amd64 (1:1.1.4-3) ...\n",
            "Selecting previously unselected package libxfixes3:amd64.\n",
            "Preparing to unpack .../13-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n",
            "Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n",
            "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
            "Preparing to unpack .../14-libdrm-amdgpu1_2.4.83-1_amd64.deb ...\n",
            "Unpacking libdrm-amdgpu1:amd64 (2.4.83-1) ...\n",
            "Selecting previously unselected package libpciaccess0:amd64.\n",
            "Preparing to unpack .../15-libpciaccess0_0.13.4-1ubuntu1_amd64.deb ...\n",
            "Unpacking libpciaccess0:amd64 (0.13.4-1ubuntu1) ...\n",
            "Selecting previously unselected package libdrm-intel1:amd64.\n",
            "Preparing to unpack .../16-libdrm-intel1_2.4.83-1_amd64.deb ...\n",
            "Unpacking libdrm-intel1:amd64 (2.4.83-1) ...\n",
            "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
            "Preparing to unpack .../17-libdrm-nouveau2_2.4.83-1_amd64.deb ...\n",
            "Unpacking libdrm-nouveau2:amd64 (2.4.83-1) ...\n",
            "Selecting previously unselected package libdrm-radeon1:amd64.\n",
            "Preparing to unpack .../18-libdrm-radeon1_2.4.83-1_amd64.deb ...\n",
            "Unpacking libdrm-radeon1:amd64 (2.4.83-1) ...\n",
            "Selecting previously unselected package libllvm5.0:amd64.\n",
            "Preparing to unpack .../19-libllvm5.0_1%3a5.0-3_amd64.deb ...\n",
            "Unpacking libllvm5.0:amd64 (1:5.0-3) ...\n",
            "Selecting previously unselected package libsensors4:amd64.\n",
            "Preparing to unpack .../20-libsensors4_1%3a3.4.0-4_amd64.deb ...\n",
            "Unpacking libsensors4:amd64 (1:3.4.0-4) ...\n",
            "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
            "Preparing to unpack .../21-libgl1-mesa-dri_17.2.8-0ubuntu0~17.10.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dri:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "Preparing to unpack .../22-libgl1-mesa-glx_17.2.8-0ubuntu0~17.10.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n",
            "Selecting previously unselected package libxi6:amd64.\n",
            "Preparing to unpack .../23-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
            "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "Preparing to unpack .../24-freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../25-libglu1-mesa_9.0.0-2.1build1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.0-2.1build1) ...\n",
            "Selecting previously unselected package python-opengl.\n",
            "Preparing to unpack .../26-python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package libtxc-dxtn-s2tc:amd64.\n",
            "Preparing to unpack .../27-libtxc-dxtn-s2tc_1.0+git20151227-2_amd64.deb ...\n",
            "Unpacking libtxc-dxtn-s2tc:amd64 (1.0+git20151227-2) ...\n",
            "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
            "Setting up libxcb-present0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libxcb-dri2-0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libxcb-dri3-0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libxcb-glx0:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libxdamage1:amd64 (1:1.1.4-3) ...\n",
            "Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n",
            "Setting up libelf1:amd64 (0.170-0.1) ...\n",
            "Setting up libxshmfence1:amd64 (1.2-1) ...\n",
            "Setting up libllvm5.0:amd64 (1:5.0-3) ...\n",
            "Setting up libtxc-dxtn-s2tc:amd64 (1.0+git20151227-2) ...\n",
            "update-alternatives: using /usr/lib/x86_64-linux-gnu/s2tc/libtxc_dxtn.so to provide /usr/lib/x86_64-linux-gnu/libtxc_dxtn.so (libtxc-dxtn-x86_64-linux-gnu) in auto mode\n",
            "Setting up libglapi-mesa:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n",
            "Setting up libdrm-common (2.4.83-1) ...\n",
            "Setting up libxcb-sync1:amd64 (1.12-1ubuntu1) ...\n",
            "Setting up libx11-xcb1:amd64 (2:1.6.4-3) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libpciaccess0:amd64 (0.13.4-1ubuntu1) ...\n",
            "Setting up libsensors4:amd64 (1:3.4.0-4) ...\n",
            "Setting up libxxf86vm1:amd64 (1:1.1.4-1) ...\n",
            "Setting up libdrm2:amd64 (2.4.83-1) ...\n",
            "Setting up libdrm-intel1:amd64 (2.4.83-1) ...\n",
            "Setting up libdrm-radeon1:amd64 (2.4.83-1) ...\n",
            "Setting up libdrm-nouveau2:amd64 (2.4.83-1) ...\n",
            "Setting up libdrm-amdgpu1:amd64 (2.4.83-1) ...\n",
            "Setting up libgl1-mesa-dri:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (17.2.8-0ubuntu0~17.10.1) ...\n",
            "update-alternatives: using /usr/lib/x86_64-linux-gnu/mesa/ld.so.conf to provide /etc/ld.so.conf.d/x86_64-linux-gnu_GL.conf (x86_64-linux-gnu_gl_conf) in auto mode\n",
            "Setting up libglu1-mesa:amd64 (9.0.0-2.1build1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uznsIosw7tg0",
        "colab_type": "code",
        "outputId": "3d2fdef7-fe0e-47ce-a5d4-6507e745ec06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2428
        }
      },
      "source": [
        "import gym\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from gym import wrappers\n",
        "\n",
        "%matplotlib inline\n",
        "# base code from udacity-deep-learning/reinforcement/Q-learning-cart.ipynb\n",
        "\n",
        "# Create class QNetwork\n",
        "class QNetwork:\n",
        "    def __init__(self, \\\n",
        "                 learning_rate=0.01, \\\n",
        "                 state_size=4, \n",
        "                 action_size=2, \\\n",
        "                 hidden_size=10, \\\n",
        "                 hidden_layers=2, \\\n",
        "                 alpha=0., \\\n",
        "                 name='QNetwork'):\n",
        "        \n",
        "        # create Q Network\n",
        "        with tf.variable_scope(name):\n",
        "            self.inputs_ = tf.placeholder(tf.float32, \\\n",
        "                                          [None, state_size], \\\n",
        "                                          name='inputs')\n",
        "            \n",
        "            # placeholder for actions, to be one-hot encoded next\n",
        "            self.actions_ = tf.placeholder(tf.int32, \\\n",
        "                                           [None], \\\n",
        "                                           name='actions')\n",
        "            \n",
        "            # one hot encode actions\n",
        "            one_hot_actions = tf.one_hot(self.actions_, \\\n",
        "                                         action_size)\n",
        "            \n",
        "            # placeholder for target Qs\n",
        "            self.targetQs_ = tf.placeholder(tf.float32, \\\n",
        "                                            [None], \\\n",
        "                                            name='target')\n",
        "            \n",
        "                \n",
        "            # ReLU hidden layers\n",
        "            self.fc1 = tf.layers.dense(self.inputs_, \\\n",
        "                                        hidden_size,\\\n",
        "                                        activation=None,\\\n",
        "                                        kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
        "            self.fc1 = tf.maximum(alpha*self.fc1,self.fc1)\n",
        "            \n",
        "            self.fc2 = tf.layers.dense(self.fc1, hidden_size,\\\n",
        "                                            activation=None,\\\n",
        "                                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
        "            self.fc2 = tf.maximum(alpha*self.fc2,self.fc2)\n",
        "                \n",
        "            out_layer = self.fc2\n",
        "            \n",
        "\n",
        "            # Linear output layer\n",
        "            self.output = tf.layers.dense(out_layer, action_size, \\\n",
        "                                          activation=None,\\\n",
        "                                          kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
        "            \n",
        "            ### Train with loss (targetQ - Q)^2\n",
        "            # output has length 2, for two actions. This next line chooses\n",
        "            # one value from output (per row) according to the one-hot encoded actions.\n",
        "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
        "            \n",
        "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
        "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
        "\n",
        "            \n",
        "# create memory class for storing previous experiences\n",
        "class Memory():\n",
        "    def __init__(self, max_size = 1000):\n",
        "        self.buffer = deque(maxlen=max_size)\n",
        "    \n",
        "    def add(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "            \n",
        "    def sample(self, batch_size):\n",
        "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
        "                               size=batch_size, \n",
        "                               replace=False)\n",
        "        return [self.buffer[ii] for ii in idx]\n",
        "\n",
        "def running_mean(x, N):\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
        "    return (cumsum[N:] - cumsum[:-N]) / N \n",
        "\n",
        "def normalize_state(x):\n",
        "    normalizer = [2.,3.,0.3,2.]\n",
        "    y = x / normalizer\n",
        "    return y\n",
        "\n",
        "def initialize_memory_rand_states(memory_size=1000,pretrain_length=32):\n",
        "    \n",
        "    # Initialize the simulation\n",
        "    # Make a random action\n",
        "    env.reset()\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, done, _ = env.step(action)\n",
        "    state = normalize_state(state)\n",
        "    \n",
        "    memory = Memory(max_size=memory_size)\n",
        "\n",
        "    # Make a bunch of random actions and store the experiences\n",
        "    ii = 0\n",
        "    while ii < pretrain_length or not done:\n",
        "        \n",
        "        # Make a random action\n",
        "        action = env.action_space.sample()\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        if done:\n",
        "            # The simulation fails so no next state\n",
        "            next_state = np.zeros(state.shape)\n",
        "            \n",
        "            # Add experience to memory\n",
        "            memory.add((state, action, reward, next_state))\n",
        "\n",
        "            # Start new episode\n",
        "            state = env.reset()\n",
        "            state = normalize_state(state)\n",
        "\n",
        "        else:\n",
        "            # Add experience to memory\n",
        "            memory.add((state, action, reward, next_state))\n",
        "            state = next_state\n",
        "        \n",
        "        ii = ii + 1\n",
        "            \n",
        "    return memory\n",
        "\n",
        "def train_q_network(mainQN,\\\n",
        "                    memory,\\\n",
        "                    train_episodes=1500,\\\n",
        "                    gamma=0.99,\\\n",
        "                    explore_start=1.0,\\\n",
        "                    explore_stop=0.01,\\\n",
        "                    decay_rate=0.0001,\\\n",
        "                    batch_size=32,\\\n",
        "                    max_steps=500,\\\n",
        "                    verbose=True):\n",
        "    \n",
        "    \n",
        "    state = env.reset()\n",
        "    state = normalize_state(state)\n",
        "    \n",
        "    # Now train with experiences\n",
        "    saver = tf.train.Saver()\n",
        "    rewards_list = []\n",
        "    with tf.Session() as sess:\n",
        "        # Initialize variables\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        step = 0\n",
        "        steps_list = []\n",
        "        \n",
        "        for ep in range(train_episodes):\n",
        "            total_reward = 0\n",
        "            t = 0\n",
        "            \n",
        "            while t < max_steps:\n",
        "                step += 1\n",
        "\n",
        "                # Explore or Exploit\n",
        "                explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
        "                if explore_p > np.random.rand():\n",
        "                    # Make a random action\n",
        "                    action = env.action_space.sample()\n",
        "                else:\n",
        "                    # Get action from Q-network\n",
        "                    state_normalizer = [2.,3.,0.3,3.]\n",
        "                    feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
        "                    Qs = sess.run(mainQN.output, feed_dict=feed)\n",
        "                    action = np.argmax(Qs)\n",
        "\n",
        "                # Take action, get new state and reward\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                next_state = normalize_state(next_state)\n",
        "                \n",
        "                total_reward += reward\n",
        "\n",
        "                if done:\n",
        "                    t = t+1\n",
        "                    # the episode ends so no next state\n",
        "                    next_state = np.zeros(state.shape)\n",
        "                    steps_list.append(t)\n",
        "                    t = max_steps\n",
        "\n",
        "                    # Add experience to memory\n",
        "                    memory.add((state, action, reward, next_state))\n",
        "                    state = env.reset()\n",
        "                    state = normalize_state(state)\n",
        "                else:\n",
        "                    # Add experience to memory\n",
        "                    memory.add((state, action, reward, next_state))\n",
        "                    state = next_state\n",
        "                    t += 1\n",
        "\n",
        "                # Sample mini-batch from memory\n",
        "                batch = memory.sample(batch_size)\n",
        "                states = np.array([each[0] for each in batch])\n",
        "                actions = np.array([each[1] for each in batch])\n",
        "                rewards = np.array([each[2] for each in batch])\n",
        "                next_states = np.array([each[3] for each in batch])\n",
        "\n",
        "                # Train network\n",
        "                target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
        "\n",
        "                # Set target_Qs to 0 for states where episode ends\n",
        "                episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
        "                target_Qs[episode_ends] = (0, 0)\n",
        "\n",
        "                targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
        "\n",
        "                loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
        "                                    feed_dict={mainQN.inputs_: states,\n",
        "                                               mainQN.targetQs_: targets,\n",
        "                                               mainQN.actions_: actions})\n",
        "            \n",
        "            rewards_list.append((ep, total_reward))   \n",
        "            runningMean = np.mean(steps_list[-100:])\n",
        "            if verbose:\n",
        "                \n",
        "                print('Episode: {}'.format(ep),\n",
        "                      'Total reward: {}'.format(total_reward),\n",
        "                      'Training loss: {:.4f}'.format(loss),\n",
        "                      'Explore P: {:.4f}'.format(explore_p),\n",
        "                      'RunMean : {:.4f}'.format(runningMean))\n",
        "               \n",
        "            \n",
        "            \n",
        "            if runningMean > 495.:\n",
        "                saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
        "                return rewards_list, mainQN, saver\n",
        "            \n",
        "        saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
        "        return rewards_list, mainQN, saver\n",
        "\n",
        "def plot_rewards(rewards_list):\n",
        "    eps, rews = np.array(rewards_list).T\n",
        "    smoothed_rews = running_mean(rews, 10)\n",
        "    plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
        "    plt.plot(eps, rews, color='grey', alpha=0.3)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "\n",
        "\n",
        "def generate_and_train_qnetwork(train_episodes=1500,\\\n",
        "                   gamma=0.99,\\\n",
        "                   explore_start=1.0,\\\n",
        "                   explore_stop=0.01,\\\n",
        "                   decay_rate=0.0001,\\\n",
        "                   hidden_size=128,\\\n",
        "                   hidden_layers=2,\\\n",
        "                   learning_rate=0.0001,\\\n",
        "                   memory_size=10000,\\\n",
        "                   batch_size=32,\\\n",
        "                   render=False,\\\n",
        "                   alpha=0.1,\\\n",
        "                   verbose=True):\n",
        "    \n",
        "    # reset graph\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    mainQN = QNetwork(name='main', hidden_size=hidden_size, \\\n",
        "                      hidden_layers=hidden_layers, learning_rate=learning_rate, alpha=alpha)\n",
        "    \n",
        "    memory = initialize_memory_rand_states(memory_size=memory_size,pretrain_length=batch_size)\n",
        "\n",
        "    \n",
        "    # train q-network\n",
        "    rewards_list, mainQN, saver = train_q_network(mainQN,\\\n",
        "                                  memory,\\\n",
        "                                  train_episodes = train_episodes, \\\n",
        "                                  gamma=gamma,\\\n",
        "                                  explore_start=explore_start,\\\n",
        "                                  explore_stop=explore_stop,\\\n",
        "                                  decay_rate=decay_rate,\\\n",
        "                                  batch_size=batch_size,\\\n",
        "                                  verbose=verbose)\n",
        "\n",
        "    if verbose:\n",
        "        # plot training\n",
        "        plot_rewards(rewards_list)\n",
        "    \n",
        "    avg_train_rewards = np.sum([each[1] for each in rewards_list]) / len(rewards_list)\n",
        "    if verbose:\n",
        "        print('average training reward = ',avg_train_rewards)\n",
        "\n",
        "    \n",
        "    return avg_train_rewards, mainQN, saver, len(rewards_list)\n",
        "\n",
        "\n",
        "# Create the environment\n",
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "# Start monitor\n",
        "env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\n",
        "\n",
        "# Train network\n",
        "avg_train_rewards, mainQN, saver, number_of_episodes = generate_and_train_qnetwork(train_episodes=1000, verbose=False)\n",
        "print('average test reward = ', avg_train_rewards,'   number of trials = ',number_of_episodes)\n",
        "\n",
        "# Close environment\n",
        "env.close"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method Monitor.__del__ of <Monitor<TimeLimit<CartPoleEnv<CartPole-v1>>>>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\", line 234, in __del__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\", line 145, in close\n",
            "    self._close_video_recorder()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\", line 217, in _close_video_recorder\n",
            "    self.video_recorder.close()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitoring/video_recorder.py\", line 129, in close\n",
            "    os.remove(self.path)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/cartpole-experiment-1/openaigym.video.0.35.video000000.mp4'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NoSuchDisplayException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-378513032ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;31m# Train network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m \u001b[0mavg_train_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_and_train_qnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'average test reward = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_train_rewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'   number of trials = '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_of_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-378513032ecc>\u001b[0m in \u001b[0;36mgenerate_and_train_qnetwork\u001b[0;34m(train_episodes, gamma, explore_start, explore_stop, decay_rate, hidden_size, hidden_layers, learning_rate, memory_size, batch_size, render, alpha, verbose)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mmainQN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'main'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m                       \u001b[0mhidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_memory_rand_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpretrain_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-378513032ecc>\u001b[0m in \u001b[0;36minitialize_memory_rand_states\u001b[0;34m(memory_size, pretrain_length)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Initialize the simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Make a random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_after_reset\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# Bump *after* all reset activity has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset_video_recorder\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_video_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_close_video_recorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/wrappers/monitoring/video_recorder.py\u001b[0m in \u001b[0;36mcapture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mrender_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ansi'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mansi_mode\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# trickery is for circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0m_pyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1894\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m     \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_shadow_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0m_shadow_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36mget_default_display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[0;32m-> 1845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/canvas/__init__.py\u001b[0m in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;31m# Otherwise, create a new display and return it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_pyglet_docgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXOpenDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDisplayException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot connect to \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mscreen_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXScreenCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Npd9HBq8pFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}