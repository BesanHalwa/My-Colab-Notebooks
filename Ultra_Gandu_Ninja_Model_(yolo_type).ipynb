{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ultra_Gandu_Ninja_Model (yolo type).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "oI4jF2mJemk7",
        "AOZqkcH6DWHW",
        "f4fjgfJm6q-1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK6HknvNp8bC",
        "colab_type": "text"
      },
      "source": [
        "# -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUVB9O75C0cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUxDNcg3C3Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iULJR-gC-wL",
        "colab_type": "code",
        "outputId": "9239ccb4-b265-49e3-f13e-217ef3c67769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/project_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/project_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B5a3LLGAanW",
        "colab_type": "code",
        "outputId": "4a56b88d-819c-42f9-e407-150214723859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Yolo_type_data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/project_data/Yolo_type_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8HTe8YGTA8q",
        "colab_type": "code",
        "outputId": "fa3ef981-c017-4ce3-cb3c-4d783fa6f665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/project_data/Yolo_type_data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64HjGRafDwKv",
        "colab_type": "code",
        "outputId": "926fa35a-1bd3-4968-cc51-da0565f72029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, Reshape\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMh9Xk0TDlV0",
        "colab_type": "code",
        "outputId": "08d397b4-1033-4d0d-9dbb-472394e10b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X = np.load('X.npy')\n",
        "Y = np.load('ninja.npy')\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21503, 300, 300, 3)\n",
            "(21503, 49, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyctbVaZp0dx",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwmphPiYC3eL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_vgg(model, shape=(300,300,3)):\n",
        "    \n",
        "    # Block 1\n",
        "    model.add(Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv1',input_shape=shape,\n",
        "                      trainable=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv2',\n",
        "                      trainable=False))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 2\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv1',\n",
        "                      trainable=False))\n",
        "    model.add(Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv2',\n",
        "                      trainable=False))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 3\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv1',\n",
        "                      trainable=False))\n",
        "    model.add(Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv2',\n",
        "                      trainable=False))\n",
        "    model.add(Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv3',\n",
        "                      trainable=False))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 4\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv1',\n",
        "                      trainable=False))\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv2',\n",
        "                      trainable=False))\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv3',\n",
        "                      trainable=False))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    # Block 5\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv1',\n",
        "                      trainable=False))\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv2',\n",
        "                      trainable=False))\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv3',\n",
        "                      trainable=False))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    return model\n",
        "\n",
        "#VGG structure model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8itO1koQDDwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_extra_layers(model):\n",
        "    #extra Block\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='extra_block_conv1'))\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='extra_block_conv2'))\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='extra_block_conv3'))\n",
        "    \n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Z8AnK0DD4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_final_layer(model):\n",
        "    \n",
        "    #final extra Block\n",
        "    model.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      name='final_block1_conv1'))\n",
        "\n",
        "    model.add(Flatten()) # 25088 output\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(4000,activation='relu'))\n",
        "    model.add(Dense(1225,activation='relu'))\n",
        "    model.add(Reshape((49, 25))) # 49*25 = 1225\n",
        "    model.add(Dense(25,activation='relu',input_shape=(49,25)))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqpZ3UimEjbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(inp_shape=(300,300,3)):\n",
        "    #Declaring Sequential model\n",
        "    model = Sequential()\n",
        "    # Loading VGG model structure\n",
        "    model = add_vgg(model)\n",
        "    \n",
        "    #model.load_weights('classifier_weights.h5',by_name=True)\n",
        "    model.load_weights('Ultra_Gandu_Ninja_Model_epoch5.h5',by_name=True)\n",
        "    model = add_extra_layers(model)\n",
        "    model = add_final_layer(model)\n",
        "    # Loading trained VGG weights to the named layers\n",
        "    \n",
        "    \n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz3W9v8nfLtr",
        "colab_type": "text"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyIpfV1zFFOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNQig_3pe5FH",
        "colab_type": "text"
      },
      "source": [
        "# Losses and Part-Wise Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDvtByraFC1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the loss function that we are optimizzing on\n",
        "\n",
        "def C_Loss(Y1, Y2):\n",
        "  \n",
        "  Y_true = tf.cast(Y1, tf.float32)\n",
        "  Y_pred = tf.cast(Y2, tf.float32)\n",
        "  \n",
        "  loss1 = tf.log(tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,0:1],Y_true[:,:,0:1]))) + 1)\n",
        "  loss2 = tf.log(tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,1:2],Y_true[:,:,1:2]))) + 1)\n",
        "  loss3 = tf.log(tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,2:3],Y_true[:,:,2:3]))) + 1)\n",
        "  loss4 = tf.log(tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,3:4],Y_true[:,:,3:4]))) + 1)\n",
        "  \n",
        "  loss5 = tf.log(tf.square(tf.subtract(Y_true[:,:,4:5],Y_pred[:,:,4:5])) + 1)\n",
        "\n",
        "  loss6 = tf.log(tf.square(tf.subtract(Y_true[:,:,5:25], Y_pred[:,:,5:25])) + 1)\n",
        "\n",
        "  return (5 * (loss1+loss2+loss3+loss4) + 0.5 * (loss5) + 0.5 * loss6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlbQhtVzGizE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def C_LossABC(Y1, Y2):\n",
        "  \n",
        "  Y_true = tf.cast(Y1, tf.float32) * 10\n",
        "  Y_pred = tf.cast(Y2, tf.float32) * 10\n",
        "  \n",
        "  loss1 = tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,0:1],Y_true[:,:,0:1])))\n",
        "  loss2 = tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,1:2],Y_true[:,:,1:2])))\n",
        "  loss3 = tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,2:3],Y_true[:,:,2:3])))\n",
        "  loss4 = tf.multiply(Y_true[:,:,4:5],tf.square(tf.subtract(Y_pred[:,:,3:4],Y_true[:,:,3:4])))\n",
        "  \n",
        "  loss5 = tf.log(tf.square(tf.subtract(Y_true[:,:,4:5],Y_pred[:,:,4:5])) + 1)\n",
        "\n",
        "  loss6 = tf.log(tf.square(tf.subtract(Y_true[:,:,5:25], Y_pred[:,:,5:25])) + 1)\n",
        "\n",
        "  return (5 * (loss1+loss2+loss3+loss4) + 0.5 * (loss5) + 0.5 * loss6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxtER3IuetOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combined accurecy for center(x, y), height(h), weidth(w)\n",
        "from keras import backend as K\n",
        "def bbox_loss(Y1, Y2):\n",
        "\n",
        "  Y_true = tf.cast(Y1[:,:,0:4], tf.float32) * 300\n",
        "  Y_pred = tf.cast(Y2[:,:,0:4], tf.float32) * 300\n",
        "  \n",
        "  return K.mean(K.square(Y_pred - Y_true), axis=-1)\n",
        "  #return tf.divide(tf.abs(tf.subtract(Y_true, Y_pred)), Y_true)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVFA7ldqg-S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class Prediction loss (categorical_cross_entropy)\n",
        "from keras import backend as K\n",
        "def class_pred_loss(Y1, Y2):\n",
        "  Y_true = tf.cast(Y1[:,:,5:], tf.float32)\n",
        "  Y_pred = tf.cast(Y2[:,:,5:], tf.float32)\n",
        "  \n",
        "  return K.categorical_crossentropy(Y_true, Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpGgjGPUh0B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI4jF2mJemk7",
        "colab_type": "text"
      },
      "source": [
        "# Training Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyLI0kmSXBuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGD(lr=0.001)\n",
        "model.compile(loss=C_LossABC,\n",
        "              optimizer=sgd,\n",
        "              metrics=[bbox_loss, class_pred_loss])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8sacQve0wWH",
        "colab_type": "code",
        "outputId": "c831fe3c-b66f-4286-fcd2-3372578192c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=25, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16000 samples, validate on 5503 samples\n",
            "Epoch 1/5\n",
            "13475/16000 [========================>.....] - ETA: 1:54 - loss: 353.9790 - bbox_loss: 1582.4964 - class_pred_loss: 5.7971e-09"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16000/16000 [==============================] - 860s 54ms/step - loss: 353.1560 - bbox_loss: 1578.7932 - class_pred_loss: 5.7739e-09 - val_loss: 351.9188 - val_bbox_loss: 1573.2268 - val_class_pred_loss: 5.5974e-09\n",
            "Epoch 2/5\n",
            " 6175/16000 [==========>...................] - ETA: 7:22 - loss: 352.7229 - bbox_loss: 1576.8441 - class_pred_loss: 5.7766e-09"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16000/16000 [==============================] - 857s 54ms/step - loss: 353.1560 - bbox_loss: 1578.7932 - class_pred_loss: 5.7739e-09 - val_loss: 351.9188 - val_bbox_loss: 1573.2268 - val_class_pred_loss: 5.5974e-09\n",
            "Epoch 3/5\n",
            " 3550/16000 [=====>........................] - ETA: 9:21 - loss: 362.2685 - bbox_loss: 1619.7985 - class_pred_loss: 5.9896e-09"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16000/16000 [==============================] - 857s 54ms/step - loss: 353.1560 - bbox_loss: 1578.7932 - class_pred_loss: 5.7739e-09 - val_loss: 351.9188 - val_bbox_loss: 1573.2268 - val_class_pred_loss: 5.5974e-09\n",
            "Epoch 4/5\n",
            " 2625/16000 [===>..........................] - ETA: 10:02 - loss: 348.5150 - bbox_loss: 1557.9091 - class_pred_loss: 5.7350e-09"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16000/16000 [==============================] - 857s 54ms/step - loss: 353.1560 - bbox_loss: 1578.7932 - class_pred_loss: 5.7739e-09 - val_loss: 351.9188 - val_bbox_loss: 1573.2268 - val_class_pred_loss: 5.5974e-09\n",
            "Epoch 5/5\n",
            " 2275/16000 [===>..........................] - ETA: 10:18 - loss: 352.3395 - bbox_loss: 1575.1192 - class_pred_loss: 5.7030e-09"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16000/16000 [==============================] - 857s 54ms/step - loss: 353.1560 - bbox_loss: 1578.7932 - class_pred_loss: 5.7739e-09 - val_loss: 351.9188 - val_bbox_loss: 1573.2268 - val_class_pred_loss: 5.5974e-09\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa7fc3a5a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkI64mRemPK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch4.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffOdlDdwGXzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FStF-S6ZPAcZ",
        "colab_type": "code",
        "outputId": "a97fda14-679c-4a1b-ffd1-46bbdaafb379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3584
        }
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=25, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16000 samples, validate on 5503 samples\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/dense_1/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/SGD/gradients/dropout_1/cond/Merge_grad/cond_grad\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge, training/SGD/gradients/dense_1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1c5649db226a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/dense_1/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/SGD/gradients/dropout_1/cond/Merge_grad/cond_grad\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge, training/SGD/gradients/dense_1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'training/SGD/gradients/dense_1/MatMul_grad/MatMul_1', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-22-1c5649db226a>\", line 1, in <module>\n    model.fit(X[0:16000], Y[0:16000], batch_size=64, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 1002, in fit\n    validation_steps=validation_steps)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1682, in fit\n    self._make_train_function()\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 992, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 173, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2519, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 532, in gradients\n    gate_gradients, aggregation_method, stop_gradients)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in _GradientsHelper\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 396, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 701, in <lambda>\n    lambda: grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py\", line 1049, in _MatMulGrad\n    grad_b = gen_math_ops.mat_mul(a, grad, transpose_a=True)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4279, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'dense_1/MatMul', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 16 identical lines from previous traceback]\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-834f03506210>\", line 1, in <module>\n    model = create_model()\n  File \"<ipython-input-16-c4743da63a3b>\", line 8, in create_model\n    model = add_final_layer(model)\n  File \"<ipython-input-15-5ec511f7856e>\", line 10, in add_final_layer\n    model.add(Dense(4000,activation='relu'))\n  File \"/usr/local/lib/python3.6/dist-packages/keras/models.py\", line 522, in add\n    output_tensor = layer(self.outputs[0])\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\", line 877, in call\n    output = K.dot(inputs, self.kernel)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 1076, in dot\n    out = tf.matmul(x, y)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\", line 2014, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 4279, in mat_mul\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25088,4000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training/SGD/gradients/dense_1/MatMul_grad/MatMul_1 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/SGD/gradients/dropout_1/cond/Merge_grad/cond_grad\"], transpose_a=true, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_1/cond/Merge, training/SGD/gradients/dense_1/Relu_grad/ReluGrad)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WuxG_oEPClp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch10.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJLj1OJtvyn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=25, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyMPpN9Hvysm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch15.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZXpJ7_avywc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=25, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJJF8Wb7vy0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch20.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlNu-kVsvy8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=25, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABFTb3ZYvy_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch25.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFp7PhjvzGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=25, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Px4vvyMvzLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch30.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_1quLDAC_NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=25, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI4qDzNOC_RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch35.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3-Z3GEXaL39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33uy1dQCiwaz",
        "colab_type": "text"
      },
      "source": [
        "# Training Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gps0KatxjZlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_weights('Ultra_Gandu_Ninja_Weights_epoch35.h5',by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZcoJpWIi0JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd = SGD(lr=0.0001)\n",
        "model.compile(loss=C_Loss,\n",
        "              optimizer=sgd,\n",
        "              metrics=[bbox_loss, class_pred_loss])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmx0mePRi0TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=64, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYgGFL2ojFD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch40.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdGBCi33nvfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=64, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDaUQiypnviV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch45.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmwkB0q3nvvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=64, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PuV67_wnvyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oUkcNQNnv6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=64, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKZYZM-Vnv9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch55.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHg0YC-Qnxas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X[0:16000], Y[0:16000], batch_size=64, epochs=5, verbose=1,validation_data=(X[16000:],Y[16000:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHByCV94nxll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('Ultra_Gandu_Ninja_Model_epoch60.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOZqkcH6DWHW",
        "colab_type": "text"
      },
      "source": [
        "# Test Preds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVJrBAFf6Bcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X[3:4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ1ylyFYw2Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred[0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyyQBpDz6B6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y[3,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTVt1_hHcN6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6nkfdHCAWuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "pred = model.predict(X[0:1])\n",
        "true = np.zeros((1,49,25), dtype='float64')\n",
        "true[0] = Y[0]\n",
        "\n",
        "error = C_Loss(true,pred)\n",
        "print(sess.run(tf.reduce_mean(error)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRVDUXiZ9Kko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4fjgfJm6q-1",
        "colab_type": "text"
      },
      "source": [
        "# Create lable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNxrA3q--P6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = np.load('49*6lable.npy')\n",
        "k = np.zeros((21503, 49, 25))\n",
        "for i in range(21503):\n",
        "  for j in range(49):\n",
        "    \n",
        "    # x, y, h**0.5, w**0.5, confidence,\n",
        "    k[i,j, 0] = Y[i,j,1]\n",
        "    k[i,j, 1] = Y[i,j,2]\n",
        "    k[i,j, 2] = Y[i,j,3] ** 0.5\n",
        "    k[i,j, 3] = Y[i,j,4] ** 0.5\n",
        "    k[i,j, 4] = Y[i,j,5]\n",
        "    \n",
        "    index = int(4 + Y[i,j,0])\n",
        "    k[i][j][index] = 1\n",
        "\n",
        "np.save(\"ninja.npy\", k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nOBrwmuCiOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gp0nvK1DyZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y[0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW1jKQ0HGZeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKWdWDqbK3tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(X[2:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvjx0WpvRsSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4st4bA_RzdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}