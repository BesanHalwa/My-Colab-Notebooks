{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier_using_vgg_weights.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFDVNHG7Ez_O",
        "colab_type": "text"
      },
      "source": [
        "#Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blWjFK7sEg9F",
        "colab_type": "code",
        "outputId": "d3c27993-8ddb-48a8-b6ca-7dbdc8764ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2380
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 18396 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cron_3.0pl1-128ubuntu5_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128ubuntu5) ...\n",
            "Selecting previously unselected package libapparmor1:amd64.\n",
            "Preparing to unpack .../01-libapparmor1_2.11.0-2ubuntu17.1_amd64.deb ...\n",
            "Unpacking libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Selecting previously unselected package libdbus-1-3:amd64.\n",
            "Preparing to unpack .../02-libdbus-1-3_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Selecting previously unselected package dbus.\n",
            "Preparing to unpack .../03-dbus_1.10.22-1ubuntu1_amd64.deb ...\n",
            "Unpacking dbus (1.10.22-1ubuntu1) ...\n",
            "Preparing to unpack .../04-gnupg_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking gnupg (2.1.15-1ubuntu8.1) over (2.1.15-1ubuntu8) ...\n",
            "Preparing to unpack .../05-gnupg-agent_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking gnupg-agent (2.1.15-1ubuntu8.1) over (2.1.15-1ubuntu8) ...\n",
            "Selecting previously unselected package dirmngr.\n",
            "Preparing to unpack .../06-dirmngr_2.1.15-1ubuntu8.1_amd64.deb ...\n",
            "Unpacking dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Selecting previously unselected package distro-info-data.\n",
            "Preparing to unpack .../07-distro-info-data_0.36ubuntu0.2_all.deb ...\n",
            "Unpacking distro-info-data (0.36ubuntu0.2) ...\n",
            "Selecting previously unselected package libkmod2:amd64.\n",
            "Preparing to unpack .../08-libkmod2_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Selecting previously unselected package kmod.\n",
            "Preparing to unpack .../09-kmod_24-1ubuntu2_amd64.deb ...\n",
            "Unpacking kmod (24-1ubuntu2) ...\n",
            "Selecting previously unselected package lsb-release.\n",
            "Preparing to unpack .../10-lsb-release_9.20160110ubuntu5_all.deb ...\n",
            "Unpacking lsb-release (9.20160110ubuntu5) ...\n",
            "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
            "Preparing to unpack .../11-libgirepository-1.0-1_1.54.1-1_amd64.deb ...\n",
            "Unpacking libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
            "Preparing to unpack .../12-gir1.2-glib-2.0_1.54.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Selecting previously unselected package iso-codes.\n",
            "Preparing to unpack .../13-iso-codes_3.75-1_all.deb ...\n",
            "Unpacking iso-codes (3.75-1) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../14-libdbus-glib-1-2_0.108-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Selecting previously unselected package python-apt-common.\n",
            "Preparing to unpack .../15-python-apt-common_1.4.0~beta3build2_all.deb ...\n",
            "Unpacking python-apt-common (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-apt.\n",
            "Preparing to unpack .../16-python3-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python3-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python3-dbus.\n",
            "Preparing to unpack .../17-python3-dbus_1.2.4-1build3_amd64.deb ...\n",
            "Unpacking python3-dbus (1.2.4-1build3) ...\n",
            "Selecting previously unselected package python3-gi.\n",
            "Preparing to unpack .../18-python3-gi_3.24.1-2build1_amd64.deb ...\n",
            "Unpacking python3-gi (3.24.1-2build1) ...\n",
            "Selecting previously unselected package module-init-tools.\n",
            "Preparing to unpack .../19-module-init-tools_24-1ubuntu2_all.deb ...\n",
            "Unpacking module-init-tools (24-1ubuntu2) ...\n",
            "Selecting previously unselected package python-apt.\n",
            "Preparing to unpack .../20-python-apt_1.4.0~beta3build2_amd64.deb ...\n",
            "Unpacking python-apt (1.4.0~beta3build2) ...\n",
            "Selecting previously unselected package python-pycurl.\n",
            "Preparing to unpack .../21-python-pycurl_7.43.0-2build2_amd64.deb ...\n",
            "Unpacking python-pycurl (7.43.0-2build2) ...\n",
            "Selecting previously unselected package python-software-properties.\n",
            "Preparing to unpack .../22-python-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package python3-software-properties.\n",
            "Preparing to unpack .../23-python3-software-properties_0.96.24.17_all.deb ...\n",
            "Unpacking python3-software-properties (0.96.24.17) ...\n",
            "Selecting previously unselected package software-properties-common.\n",
            "Preparing to unpack .../24-software-properties-common_0.96.24.17_all.deb ...\n",
            "Unpacking software-properties-common (0.96.24.17) ...\n",
            "Selecting previously unselected package unattended-upgrades.\n",
            "Preparing to unpack .../25-unattended-upgrades_0.98ubuntu1.1_all.deb ...\n",
            "Unpacking unattended-upgrades (0.98ubuntu1.1) ...\n",
            "Setting up python-apt-common (1.4.0~beta3build2) ...\n",
            "Setting up python3-apt (1.4.0~beta3build2) ...\n",
            "Setting up iso-codes (3.75-1) ...\n",
            "Setting up distro-info-data (0.36ubuntu0.2) ...\n",
            "Setting up python-pycurl (7.43.0-2build2) ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting up lsb-release (9.20160110ubuntu5) ...\r\n",
            "Setting up libgirepository-1.0-1:amd64 (1.54.1-1) ...\n",
            "Setting up libkmod2:amd64 (24-1ubuntu2) ...\n",
            "Setting up gir1.2-glib-2.0:amd64 (1.54.1-1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up libapparmor1:amd64 (2.11.0-2ubuntu17.1) ...\n",
            "Setting up unattended-upgrades (0.98ubuntu1.1) ...\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/20auto-upgrades with new version\n",
            "\n",
            "Creating config file /etc/apt/apt.conf.d/50unattended-upgrades with new version\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up gnupg-agent (2.1.15-1ubuntu8.1) ...\n",
            "Setting up dirmngr (2.1.15-1ubuntu8.1) ...\n",
            "Setting up cron (3.0pl1-128ubuntu5) ...\n",
            "Adding group `crontab' (GID 102) ...\n",
            "Done.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "update-rc.d: warning: stop runlevel arguments (1) do not match cron Default-Stop values (none)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libdbus-1-3:amd64 (1.10.22-1ubuntu1) ...\n",
            "Setting up kmod (24-1ubuntu2) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.108-2) ...\n",
            "Setting up gnupg (2.1.15-1ubuntu8.1) ...\n",
            "Setting up python3-gi (3.24.1-2build1) ...\n",
            "Setting up module-init-tools (24-1ubuntu2) ...\n",
            "Setting up python3-software-properties (0.96.24.17) ...\n",
            "Setting up dbus (1.10.22-1ubuntu1) ...\n",
            "Setting up python-apt (1.4.0~beta3build2) ...\n",
            "Setting up python3-dbus (1.2.4-1build3) ...\n",
            "Setting up python-software-properties (0.96.24.17) ...\n",
            "Setting up software-properties-common (0.96.24.17) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Processing triggers for dbus (1.10.22-1ubuntu1) ...\n",
            "gpg: keybox '/tmp/tmp9pbqgd_o/pubring.gpg' created\n",
            "gpg: /tmp/tmp9pbqgd_o/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Selecting previously unselected package libfuse2:amd64.\n",
            "(Reading database ... 19804 files and directories currently installed.)\n",
            "Preparing to unpack .../libfuse2_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package fuse.\n",
            "Preparing to unpack .../fuse_2.9.7-1ubuntu1_amd64.deb ...\n",
            "Unpacking fuse (2.9.7-1ubuntu1) ...\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.6.21-0ubuntu2_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n",
            "Setting up libfuse2:amd64 (2.9.7-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.26-0ubuntu2.1) ...\n",
            "Setting up fuse (2.9.7-1ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.6.21-0ubuntu2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEhjLRKHEn3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlAwVu60EsJU",
        "colab_type": "code",
        "outputId": "2c6258b9-8bb2-4e9b-f44d-704c3e05adf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Dv6bdIGEs5y",
        "colab_type": "code",
        "outputId": "a8722dda-b773-48d5-abec-16b1a63b0838",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd pascal_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/pascal_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hywNz8HHExlb",
        "colab_type": "code",
        "outputId": "8af8d758-cbcd-4c1f-b115-2e8bcac56f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier_using_vgg_weights.h5  pascaly_val.npy\r\n",
            "pascalX.npy                      pre_layers_1.h5\r\n",
            "pascalX_val.npy                  pre_layers.h5\r\n",
            "pascaly.npy                      vgg16_weights_tf_dim_ordering_tf_kernels.h5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLjUk8MDE8fi",
        "colab_type": "text"
      },
      "source": [
        "#Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tSapXl8EyL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBmBuwvbFANJ",
        "colab_type": "code",
        "outputId": "d4ab3298-1f61-40d4-f093-1eba8c86b700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X = np.load('pascalX.npy')\n",
        "Y = np.load('pascaly.npy')\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16551, 300, 300, 3)\n",
            "(16551, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2wExiHjFCjE",
        "colab_type": "code",
        "outputId": "606f6613-4ab0-4066-89bb-9d32a1c0499a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_val = np.load('pascalX_val.npy')\n",
        "Y_val = np.load('pascaly_val.npy')\n",
        "\n",
        "print(X_val.shape)\n",
        "print(Y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4952, 300, 300, 3)\n",
            "(4952, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqvHN0tNFLsn",
        "colab_type": "text"
      },
      "source": [
        "#Load VGG16 and weights\n",
        "\n",
        "weight is in the drive folder - \n",
        "\n",
        "drive/pascal_data/vgg16_weights_tf_dim_ordering_tf_kernels.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jskdslujFJ0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-5XTkH5FuzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9UxyFB9FqhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "img_path = 'elephant.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "features = model.predict(x)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soYfEFbVHGfD",
        "colab_type": "text"
      },
      "source": [
        "#VGG16 Model Defination\n",
        "\n",
        "\n",
        "\"\"\"VGG16 model for Keras.\n",
        "\n",
        "# Reference\n",
        "\n",
        "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](\n",
        "    https://arxiv.org/abs/1409.1556)\n",
        "\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "\n",
        "from . import get_keras_submodule\n",
        "\n",
        "backend = get_keras_submodule('backend')\n",
        "engine = get_keras_submodule('engine')\n",
        "layers = get_keras_submodule('layers')\n",
        "models = get_keras_submodule('models')\n",
        "keras_utils = get_keras_submodule('utils')\n",
        "\n",
        "from . import imagenet_utils\n",
        "from .imagenet_utils import decode_predictions\n",
        "from .imagenet_utils import _obtain_input_shape\n",
        "\n",
        "preprocess_input = imagenet_utils.preprocess_input\n",
        "\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                'releases/download/v0.1/'\n",
        "                'vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
        "                       'releases/download/v0.1/'\n",
        "                       'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "\n",
        "\n",
        "def VGG16(include_top=True,\n",
        "          weights='imagenet',\n",
        "          input_tensor=None,\n",
        "          input_shape=None,\n",
        "          pooling=None,\n",
        "          classes=1000):\n",
        "    \"\"\"Instantiates the VGG16 architecture.\n",
        "\n",
        "    Optionally loads weights pre-trained on ImageNet.\n",
        "    Note that the data format convention used by the model is\n",
        "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
        "\n",
        "    # Arguments\n",
        "        include_top: whether to include the 3 fully-connected\n",
        "            layers at the top of the network.\n",
        "        weights: one of `None` (random initialization),\n",
        "              'imagenet' (pre-training on ImageNet),\n",
        "              or the path to the weights file to be loaded.\n",
        "        input_tensor: optional Keras tensor\n",
        "            (i.e. output of `layers.Input()`)\n",
        "            to use as image input for the model.\n",
        "        input_shape: optional shape tuple, only to be specified\n",
        "            if `include_top` is False (otherwise the input shape\n",
        "            has to be `(224, 224, 3)`\n",
        "            (with `channels_last` data format)\n",
        "            or `(3, 224, 224)` (with `channels_first` data format).\n",
        "            It should have exactly 3 input channels,\n",
        "            and width and height should be no smaller than 48.\n",
        "            E.g. `(200, 200, 3)` would be one valid value.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model will be\n",
        "                the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a 2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        classes: optional number of classes to classify images\n",
        "            into, only to be specified if `include_top` is True, and\n",
        "            if no `weights` argument is specified.\n",
        "\n",
        "    # Returns\n",
        "        A Keras model instance.\n",
        "\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `weights`,\n",
        "            or invalid input shape. *italicized text*\n",
        "    \"\"\"\n",
        "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization), `imagenet` '\n",
        "                         '(pre-training on ImageNet), '\n",
        "                         'or the path to the weights file to be loaded.')\n",
        "\n",
        "    if weights == 'imagenet' and include_top and classes != 1000:\n",
        "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
        "                         ' as true, `classes` should be 1000')\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=224,\n",
        "                                      min_size=48,\n",
        "                                      data_format=backend.image_data_format(),\n",
        "                                      require_flatten=include_top,\n",
        "                                      weights=weights)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "        if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv1')(img_input)\n",
        "    x = layers.Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv1')(x)\n",
        "    x = layers.Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv1')(x)\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv2')(x)\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv1')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv2')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv1')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv2')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = layers.Flatten(name='flatten')(x)\n",
        "        x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
        "        x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = engine.get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='vgg16')\n",
        "\n",
        "    # Load weights.\n",
        "    if weights == 'imagenet':\n",
        "        if include_top:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                file_hash='64373286793e3c8b2b4e3219cbf3544b')\n",
        "        else:\n",
        "            weights_path = keras_utils.get_file(\n",
        "                'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                file_hash='6d6bbae143d832006294945121d1f1fc')\n",
        "        model.load_weights(weights_path)\n",
        "        if backend.backend() == 'theano':\n",
        "            keras_utils.convert_all_kernels_in_model(model)\n",
        "    elif weights is not None:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv-gxLTsJIY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "def VGG16(include_top=True,\n",
        "          weights='imagenet',\n",
        "          input_tensor=None,\n",
        "          input_shape=None,\n",
        "          pooling=None,\n",
        "          classes=1000):\n",
        "\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv1')(img_input)\n",
        "    x = layers.Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv1')(x)\n",
        "    x = layers.Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv2')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv1')(x)\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv2')(x)\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv1')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv2')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv1')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv2')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv3')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    if include_top:\n",
        "        # Classification block\n",
        "        x = layers.Flatten(name='flatten')(x)\n",
        "        x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
        "        x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
        "        x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "        if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "\n",
        "    # Create model.\n",
        "    model = models.Model(inputs, x, name='vgg16')\n",
        "\n",
        "\n",
        "    return model\n",
        "  \"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rss63plWFz4T",
        "colab_type": "text"
      },
      "source": [
        "#Build custom model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gAsXZeWQ5ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense \n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers,losses\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3LiZWlOF4Oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Sequential()\n",
        "\n",
        "# Block 1\n",
        "x.add(Conv2D(64, (3, 3),activation='relu',padding='same',name='Custom_block1_conv1',input_shape=(300,300,3)))\n",
        "x.add(Conv2D(64, (3, 3),activation='relu',padding='same',name='block1_conv2',trainable=False))\n",
        "x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
        "\n",
        "# Block 2\n",
        "x.add(Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv1',trainable=False))\n",
        "\n",
        "x.add(Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv2',trainable=False))\n",
        "\n",
        "x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
        "\n",
        "# Block 3\n",
        "x.add(Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv1',trainable=False))\n",
        "x.add(Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv2',trainable=False))\n",
        "x.add(Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv3',trainable=False))\n",
        "x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
        "\n",
        "# Block 4\n",
        "x.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv1',trainable=False))\n",
        "x.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv2',trainable=False))\n",
        "x.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv3',trainable=False))\n",
        "x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
        "\n",
        "# Block 5\n",
        "x.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv1',trainable=False))\n",
        "x.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv2',trainable=False))\n",
        "x.add(Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv3',trainable=False))\n",
        "x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
        "x.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "\n",
        "# Classification block\n",
        "x.add(Flatten(name='flatten'))\n",
        "\n",
        "x.add(Dense(4096, activation='relu', name='x_fc1'))\n",
        "# x.add(Dense(4096, activation='relu', name='fc2'))\n",
        "x.add(Dense(400, activation='relu', name='f_c2'))\n",
        "x.add(Dense(20, activation='softmax', name='coustom_predictions'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQWeRNgMNdUM",
        "colab_type": "text"
      },
      "source": [
        "## compile the model and train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4saWWupONZ6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# original parameters (lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# original parameters (lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "nadam = optimizers.Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
        "\n",
        "# original parameters (lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "adam = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "# categorical_crossentropy\n",
        "# mean_squared_error\n",
        "x.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSESQn1HNi8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels.h5',by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnKlQb6QSXPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x.load_weights('Classifier_using_vgg_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAG9hD4kRhuX",
        "colab_type": "code",
        "outputId": "2f1d2514-b75b-4d96-a390-aa563252f3a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "x.fit(X,Y,\n",
        "          epochs=5,\n",
        "          batch_size=15\n",
        "         )\n",
        "\n",
        "# score = model.evaluate(X_test, Y_test, batch_size=32)\n",
        "# print(\"--------------------------------------------\")\n",
        "# print(\"Score is\",score)\n",
        "\n",
        "# save weights\n",
        "x.save_weights('Classifier_using_vgg_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "16545/16551 [============================>.] - ETA: 0s - loss: 18.6617 - acc: 0.1272"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16551/16551 [==============================] - 889s 54ms/step - loss: 18.6618 - acc: 0.1272\n",
            "Epoch 2/5\n",
            " 5445/16551 [========>.....................] - ETA: 9:56 - loss: 18.5602 - acc: 0.1302"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16551/16551 [==============================] - 888s 54ms/step - loss: 18.6618 - acc: 0.1272\n",
            "Epoch 3/5\n",
            " 2865/16551 [====>.........................] - ETA: 12:13 - loss: 18.4978 - acc: 0.1305"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16551/16551 [==============================] - 886s 54ms/step - loss: 18.6618 - acc: 0.1272\n",
            "Epoch 4/5\n",
            " 1680/16551 [==>...........................] - ETA: 13:14 - loss: 18.4878 - acc: 0.1095"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16551/16551 [==============================] - 889s 54ms/step - loss: 18.6618 - acc: 0.1272\n",
            "Epoch 5/5\n",
            " 1125/16551 [=>............................] - ETA: 13:45 - loss: 18.9119 - acc: 0.1298"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "16551/16551 [==============================] - 887s 54ms/step - loss: 18.6618 - acc: 0.1272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ZN9q4YzF3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.save_weights('Classifier_using_vgg_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v41Td5w1joJD",
        "colab_type": "code",
        "outputId": "23ac7226-f806-4f71-ef0f-f21a3484933c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "from keras import models\n",
        "x = models.load_model('Classifier_using_vgg_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d8925a398f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classifier_using_vgg_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No model found in config file."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NMru04UqCGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}