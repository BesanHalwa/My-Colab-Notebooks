# -*- coding: utf-8 -*-
"""Abhishek_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uWNX_SaExiAAvEsW0nkPcqT9WbDEsQD_
"""

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

!mkdir -p drive
!google-drive-ocamlfuse drive



import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,Reshape
from keras import backend as k
import matplotlib.pyplot as plt
import numpy as np
from keras.layers.normalization import BatchNormalization

#######################################
############## Data Loading ###########
#######################################

X = np.load('40000.npy')
Y = np.load('Y_coco.npy')

X_train = X[0:35000]/255
Y_train = Y[0:35000]
X_test = X[35000:40000]/255
Y_test = Y[35000:40000]

#######################################
############## Data Loading ###########
#######################################

from keras import optimizers
from keras import losses

input_shape = (300,300,3)
num_category = 91

model = Sequential()


model.add(Conv2D(100,(3, 3),activation='relu',input_shape=input_shape))
model.add(BatchNormalization())
model.add(Conv2D(100, (3, 3), activation='relu'))
model.add(Conv2D(200, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(200, (3, 3), activation='softmax'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(200, (2, 2), activation='softmax'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(200, (2, 2), activation='softmax'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(200, (2, 2), activation='softmax'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(200, (2, 2), activation='softmax'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(200, (2, 2), activation='softmax'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())
model.add(Flatten())
model.add(BatchNormalization())
model.add(Dense(num_category,activation='softmax'))

adm = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)



model.compile(loss=losses.categorical_crossentropy, 
              optimizer=adm,
              metrics=['accuracy'])

batch_size = 20
num_epoch = 10
#model training
model_log = model.fit(X_train,Y_train,
          batch_size=batch_size,
          epochs=num_epoch,
          verbose=1,
          validation_data=(X_test,Y_test))

res = model.predict(X_train[0:1])

res.shape



