{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15 AUG.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8LKrjNjfyVw",
        "colab_type": "code",
        "outputId": "0dd9b2c7-24c1-41c7-ec9f-bcae8478cac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8-V-PGhf8xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j88Wme_if81J",
        "colab_type": "code",
        "outputId": "8078753e-7543-455b-95dd-3b455c7006f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd drive/project_data/Yolo_type_data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/project_data/Yolo_type_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzJwwl8mf83W",
        "colab_type": "code",
        "outputId": "a8eec983-90eb-46d3-9fcd-ba9cceed1f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49*6lable.npy          Ultra_Gandu_Ninja_Model_epoch5.h5\r\n",
            "a.h5                   X.npy\r\n",
            "classifier_weights.h5  Y.npy\r\n",
            "detector.h5            YOLO_PASCAL_labels.npy\r\n",
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/                 Yolo_type_data.ipynb\r\n",
            "model_fifteen          Yshape.npy\r\n",
            "model_five\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APCBCsb3f86Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU, Softmax\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TirXX5Vgf889",
        "colab_type": "code",
        "outputId": "80fa4212-9db2-467e-bc80-ceaa2b3c283f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X = np.load('X.npy')\n",
        "Y = np.load('Yshape.npy')\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21503, 300, 300, 3)\n",
            "(21503, 9, 9, 5, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVzQcEzGf8_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "B = np.ones((21503,9,9,5,4), dtype='float32')\n",
        "for b in range(21503):\n",
        "  for i in range(9):\n",
        "    for j in range(9):\n",
        "      for k in range(5):\n",
        "        \n",
        "        B[b,i,j,0,0] = i * 33.33 + 15\n",
        "        B[b,i,j,0,1] = j * 33.33 + 15\n",
        "        B[b,i,j,0,2] = 15\n",
        "        B[b,i,j,0,3] = 15\n",
        "        \n",
        "        B[b,i,j,1,0] = i * 33.33 + 15\n",
        "        B[b,i,j,1,1] = j * 33.33 + 15\n",
        "        B[b,i,j,1,2] = 35 \n",
        "        B[b,i,j,1,3] = 35\n",
        "        \n",
        "        B[b,i,j,2,0] = i * 33.33 + 15\n",
        "        B[b,i,j,2,1] = j * 33.33 + 15\n",
        "        B[b,i,j,2,2] = 50\n",
        "        B[b,i,j,2,3] = 80\n",
        "        \n",
        "        B[b,i,j,3,0] = i * 33.33 + 15\n",
        "        B[b,i,j,3,1] = j * 33.33 + 15\n",
        "        B[b,i,j,3,2] = 100\n",
        "        B[b,i,j,3,3] = 100\n",
        "        \n",
        "        B[b,i,j,4,0] = i * 33.33 + 15\n",
        "        B[b,i,j,4,1] = j * 33.33 + 15\n",
        "        B[b,i,j,4,2] = 140\n",
        "        B[b,i,j,4,3] = 80\n",
        "\n",
        "B = B / 300 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFUmacgHf9CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABELS = ['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
        "IMAGE_H, IMAGE_W = 300, 300\n",
        "GRID_H,  GRID_W  = 9 , 9\n",
        "BOX              = 5\n",
        "CLASS            = len(LABELS)\n",
        "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
        "OBJ_THRESHOLD    = 0.3#0.5\n",
        "NMS_THRESHOLD    = 0.3#0.45\n",
        "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
        "\n",
        "NO_OBJECT_SCALE  = 1.0\n",
        "OBJECT_SCALE     = 5.0\n",
        "COORD_SCALE      = 1.0\n",
        "CLASS_SCALE      = 1.0\n",
        "\n",
        "BATCH_SIZE       = 16\n",
        "WARM_UP_BATCHES  = 0\n",
        "TRUE_BOX_BUFFER  = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48I3BXQIgVW8",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8od4ABF2f9Ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wexEg0whgRzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
        "def space_to_depth_x2(x):\n",
        "    return tf.space_to_depth(x, block_size=2)\n",
        "\n",
        "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
        "#true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
        "true_boxes  = Input(shape=(9, 9, 5 , 4))\n",
        "\n",
        "#############################################################\n",
        "####### VGG16 Model  ########################################\n",
        "#############################################################\n",
        "# Block 1\n",
        "x = layers.Conv2D(64, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block1_conv1')(input_image)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(64, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block1_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "# Block 2\n",
        "x = layers.Conv2D(128, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block2_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(128, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block2_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "# Block 3\n",
        "x = layers.Conv2D(256, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block3_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(256, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block3_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(256, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block3_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "# Block 4\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block4_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block4_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block4_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "# Block 5\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block5_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block5_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block5_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "#x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "#############################################################\n",
        "######## Skip connection  ###################################\n",
        "#############################################################\n",
        "\n",
        "skip_connection = x\n",
        "\n",
        "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "#############################################################\n",
        "######## Extra Layers  ######################################\n",
        "#############################################################\n",
        "\n",
        "# Block 6\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block6_conv1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  name='block6_conv2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = layers.Conv2D(512, (3, 3),\n",
        "                  activation='softmax',\n",
        "                  padding='same',\n",
        "                  name='block6_conv3')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Block 7\n",
        "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
        "skip_connection = BatchNormalization()(skip_connection)\n",
        "skip_connection = Softmax(axis=-1)(skip_connection)\n",
        "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\n",
        "\n",
        "# Merge\n",
        "x = concatenate([skip_connection, x])\n",
        "\n",
        "\n",
        "\n",
        "# Block 8\n",
        "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x) \n",
        "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
        "\n",
        "\n",
        "# small hack to allow true_boxes to be registered when Keras build the model \n",
        "# for more information: https://github.com/fchollet/keras/issues/2790\n",
        "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
        "\n",
        "\n",
        "\n",
        "model = Model([input_image, true_boxes], output)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdybUE3Rgbcu",
        "colab_type": "text"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBfsNne1gR2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def closs(Y_true, Y_pred):\n",
        "    \n",
        "    \"\"\"\n",
        "    Y_true.shape = (batch_size, 49, 6)\n",
        "    6 => x, y, h, w, confidence, class\n",
        "\n",
        "    Y_pred.shape = (batch_size, 9, 9, 5, 25)\n",
        "    9 x 9 cells\n",
        "    5 frames per cell \n",
        "    25 preds per frame (x, y, h, w, confidence, [20 class preddiction] )\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    Here xi = 9, yi = 9, frames = 5, preds = 25 \n",
        "    \"\"\"\n",
        "    \n",
        "    ############################################################################\n",
        "    ###### The code below can be implemented in the loss function itself########\n",
        "    ######### However, as of now we have Y_data in such shape###################\n",
        "    ############################################################################\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    batch_size, xi, yi, frames, preds = Y_pred.shape\n",
        "\n",
        "    # mask Y_true\n",
        "    #Y = np.zeros((batch_size, xi, yi, frames, preds))\n",
        "    Y = np.zeros((16, 9, 9, 5, 25))\n",
        "\n",
        "    \n",
        "    #for i in range(batch_size):\n",
        "    for i in range(16):\n",
        "        for j in range(49):\n",
        "            # if confidence is greater than 0\n",
        "            \n",
        "            #if(Y_true[_,_,_] > 0):  \n",
        "                \n",
        "              #cell_x = tf.cast(tf.floor(tf.divide(tf.multiply(Y_true[i,j,0], 300), 9)), dtype=tf.int32)\n",
        "              #cell_y = tf.cast(tf.floor(tf.divide(tf.multiply(Y_true[i,j,1], 300), 9)), dtype=tf.int32)\n",
        "              \n",
        "              alpha, beta = Y_true[i,j,0], Y_true[i,j,0]\n",
        "              \n",
        "              cell_x = int((alpha * 300) // 33.3333)\n",
        "              cell_y = int((beta * 300) // 33.3333)\n",
        "\n",
        "\n",
        "              # mask confidence\n",
        "              Y[i,cell_x,cell_y,0:5,4] = Y_true[i,j,4]\n",
        "\n",
        "              # mask center\n",
        "              Y[i,cell_x,cell_y,0:5,0] = Y_true[i,j,0]\n",
        "              Y[i,cell_x,cell_y,0:5,1] = Y_true[i,j,1]\n",
        "\n",
        "              # mask class\n",
        "              cl_index = int(Y_true[i,j,5] + 5) \n",
        "              Y[i,cell_x,cell_y,0:5,cl_index] = 1\n",
        "\n",
        "              # mask h and w (sqrt of height and width)\n",
        "              Y[i,cell_x,cell_y,0:5,2] = Y_true[i,j,2] ** (0.5)\n",
        "              Y[i,cell_x,cell_y,0:5,3] = Y_true[i,j,3] ** (0.5)\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    #########################################################################################################\n",
        "    ############################ Loss1, not working properly ###############################################\n",
        "    #########################################################################################################\n",
        "    \n",
        "    \n",
        "    # epsilon is small value to avoid division from zero\n",
        "    epsilon = 0.1\n",
        "    \n",
        "    # Now we have Y and Y_pred\n",
        "    # Reshapr Y & Y_pred\n",
        "    \n",
        "    Y = Y_true # Remove this line when above code is implemented\n",
        "    \n",
        "    Y = tf.reshape(Y,[-1,81,5,25])\n",
        "    Y_pred = tf.reshape(Y_pred,[-1,81,5,25])\n",
        "    \n",
        "    # loss x, y, h & w\n",
        "    # (abs (divide with pred confidence ( multiply with true confidence ( square ( difference ) ) ) ) )\n",
        "    lossx = tf.multiply((tf.multiply(tf.square(tf.subtract(Y[:,:,:,0],Y_pred[:,:,:,0])), Y[:,:,:,4]) ), 2)\n",
        "    lossy = tf.multiply((tf.multiply(tf.square(tf.subtract(Y[:,:,:,1],Y_pred[:,:,:,1])), Y[:,:,:,4]) ), 2)\n",
        "    lossh = tf.multiply((tf.multiply(tf.square(tf.subtract(Y[:,:,:,2],Y_pred[:,:,:,2])), Y[:,:,:,4]) ), 5)\n",
        "    lossw = tf.multiply((tf.multiply(tf.square(tf.subtract(Y[:,:,:,3],Y_pred[:,:,:,3])), Y[:,:,:,4]) ), 5)\n",
        "    \n",
        "    # loss conf for object \n",
        "    loss_obj = tf.multiply(tf.multiply(tf.square(tf.subtract(Y[:,:,:,4], Y_pred[:,:,:,4])), Y[:,:,:,4]), 5)\n",
        "    # loss conf for no obj\n",
        "    loss_noobj = tf.square(tf.subtract(Y[:,:,:,4], Y_pred[:,:,:,4])) * 0.5\n",
        "    # loss class\n",
        "    \"\"\"\n",
        "    #loss_cl = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y[:,:,:,5:25], logits=Y[:,:,:,5:25])\n",
        "    #loss_cl = tf.reduce_sum(loss_cl * 1) \n",
        "    \"\"\"\n",
        "    loss_cl = tf.multiply(tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Y_pred[:,:,:,5:25], labels=Y[:,:,:,5:25])), 8)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    #########################################################################################################\n",
        "    ##################################### Trying loss2 ######################################################\n",
        "    #########################################################################################################\n",
        "  \n",
        "    # Now we have Y and Y_pred\n",
        "    # Reshapr Y & Y_pred\n",
        "    \n",
        "    Y = Y_true # Remove this line when above code is implemented\n",
        "    \n",
        "    Y = tf.reshape(Y,[-1,81,5,25])\n",
        "    Y_pred = tf.reshape(Y_pred,[-1,81,5,25])\n",
        "    \n",
        "    # loss x, y, h & w\n",
        "    # (abs (divide with pred confidence ( multiply with true confidence ( square ( difference ) ) ) ) )\n",
        "    lossx = tf.reduce_mean((tf.multiply(tf.square(tf.subtract(Y[:,:,:,0],Y_pred[:,:,:,0])), Y[:,:,:,4]) ))\n",
        "    lossy = tf.reduce_mean((tf.multiply(tf.square(tf.subtract(Y[:,:,:,1],Y_pred[:,:,:,1])), Y[:,:,:,4]) ))\n",
        "    lossh = tf.reduce_mean((tf.multiply(tf.square(tf.subtract(Y[:,:,:,2],Y_pred[:,:,:,2])), Y[:,:,:,4]) ))\n",
        "    lossw = tf.reduce_mean((tf.multiply(tf.square(tf.subtract(Y[:,:,:,3],Y_pred[:,:,:,3])), Y[:,:,:,4]) ))\n",
        "    \n",
        "    # loss conf for object \n",
        "    loss_obj = tf.reduce_mean((tf.multiply(tf.square(tf.subtract(Y[:,:,:,4], Y_pred[:,:,:,4])), Y[:,:,:,4])))\n",
        "    # loss conf for no obj\n",
        "    loss_noobj = tf.reduce_mean(tf.square(tf.subtract(Y[:,:,:,4], Y_pred[:,:,:,4])) * 0.5)\n",
        "    # loss class\n",
        "    loss_cl = tf.reduce_mean(tf.multiply(tf.nn.softmax_cross_entropy_with_logits(logits=Y_pred[:,:,:,5:25], labels=Y[:,:,:,5:25]), 2))\n",
        "\n",
        "    loss1 = lossx + lossy + lossh + lossw\n",
        "    loss2 = loss_noobj + loss_obj\n",
        "    loss3 = loss_cl\n",
        "    \n",
        "    loss = loss1 + loss2 + loss3\n",
        "    \n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxKk1Pb5CEhW",
        "colab_type": "code",
        "outputId": "2305877d-91c5-4b9a-ddb5-e2a91d3a095f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def box_acc(Y_true, Y_pred):\n",
        "    \n",
        "    Y_true = tf.cast(tf.reshape(Y_true,[-1,81,5,25]), dtype=tf.float64)\n",
        "    Y_pred = tf.cast(tf.reshape(Y_pred,[-1,81,5,25]), dtype=tf.float64)\n",
        "    \n",
        "    # loss x, y, h & w\n",
        "\n",
        "    lossx = tf.reduce_mean(tf.multiply(tf.square(tf.subtract(Y_true[:,:,:,0],Y_pred[:,:,:,0])), Y_true[:,:,:,4]))\n",
        "    lossy = tf.reduce_mean(tf.multiply(tf.square(tf.subtract(Y_true[:,:,:,1],Y_pred[:,:,:,1])), Y_true[:,:,:,4]))\n",
        "    lossh = tf.reduce_mean(tf.multiply(tf.square(tf.subtract(Y_true[:,:,:,2],Y_pred[:,:,:,2])), Y_true[:,:,:,4]))\n",
        "    lossw = tf.reduce_mean(tf.multiply(tf.square(tf.subtract(Y_true[:,:,:,3],Y_pred[:,:,:,3])), Y_true[:,:,:,4]))\n",
        "    \n",
        "    return (lossx + lossy + lossh + lossw)\n",
        "  \n",
        "\"\"\"\n",
        "def class_acc(Y_true, Y_pred):\n",
        "  \n",
        "    Y_true = tf.cast(tf.reshape(Y_true,[-1,81,5,25]), dtype=tf.float64)\n",
        "    Y_pred = tf.cast(tf.reshape(Y_pred,[-1,81,5,25]), dtype=tf.float64)\n",
        "    loss_cl = tf.nn.softmax_cross_entropy_with_logits(logits=Y_pred[:,:,:,5:25], labels=Y[:,:,:,5:25])\n",
        "    \n",
        "    return loss_cl\n",
        "  \n",
        "  \n",
        "def conf_acc(Y_true, Y_pred):\n",
        "  \n",
        "    Y_true = tf.cast(tf.reshape(Y_true,[-1,81,5,25]), dtype=tf.float64)\n",
        "    Y_pred = tf.cast(tf.reshape(Y_pred,[-1,81,5,25]), dtype=tf.float64)\n",
        "    loss_obj = tf.reduce_mean(tf.multiply(tf.square(tf.subtract(Y_true[:,:,:,4], Y_pred[:,:,:,4])), Y_true[:,:,:,4]))\n",
        "    \n",
        "    return loss_obj\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef class_acc(Y_true, Y_pred):\\n  \\n    Y_true = tf.cast(tf.reshape(Y_true,[-1,81,5,25]), dtype=tf.float64)\\n    Y_pred = tf.cast(tf.reshape(Y_pred,[-1,81,5,25]), dtype=tf.float64)\\n    loss_cl = tf.nn.softmax_cross_entropy_with_logits(logits=Y_pred[:,:,:,5:25], labels=Y[:,:,:,5:25])\\n    \\n    return loss_cl\\n  \\n  \\ndef conf_acc(Y_true, Y_pred):\\n  \\n    Y_true = tf.cast(tf.reshape(Y_true,[-1,81,5,25]), dtype=tf.float64)\\n    Y_pred = tf.cast(tf.reshape(Y_pred,[-1,81,5,25]), dtype=tf.float64)\\n    loss_obj = tf.reduce_mean(tf.multiply(tf.square(tf.subtract(Y_true[:,:,:,4], Y_pred[:,:,:,4])), Y_true[:,:,:,4]))\\n    \\n    return loss_obj\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7veG14UoggLE",
        "colab_type": "text"
      },
      "source": [
        "# Load Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFqsfyMngR48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('classifier_weights.h5',by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74AiEprGgl3M",
        "colab_type": "text"
      },
      "source": [
        "# Compile & Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bUborFsgR7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "optimizer = SGD(lr=0.001, decay=0.0, momentum=0.9)\n",
        "#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(loss=closs, optimizer=optimizer, metrics=['accuracy', box_acc])\n",
        "\n",
        "# metrics=['accuracy', box_acc, class_acc, conf_acc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nG9wvkEgR-p",
        "colab_type": "code",
        "outputId": "865532a2-f9d4-401a-ada6-3842dd3d15a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.fit([X, B], Y, batch_size=24, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21503/21503 [==============================] - 1637s 76ms/step - loss: 0.2687 - acc: 0.0782 - box_acc: 0.0067\n",
            "Epoch 2/5\n",
            "21503/21503 [==============================] - 1616s 75ms/step - loss: 0.2260 - acc: 0.1808 - box_acc: 0.0076\n",
            "Epoch 3/5\n",
            "21503/21503 [==============================] - 1608s 75ms/step - loss: 2234.3406 - acc: 0.0700 - box_acc: 0.0114\n",
            "Epoch 4/5\n",
            "21503/21503 [==============================] - 1606s 75ms/step - loss: 2752.4485 - acc: 0.1233 - box_acc: 0.0152\n",
            "Epoch 5/5\n",
            "21503/21503 [==============================] - 1558s 72ms/step - loss: nan - acc: 0.5801 - box_acc: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff7f0fb0048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJKIlFzmv9dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('a.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLSKEZ7Ov9gD",
        "colab_type": "code",
        "outputId": "932c204c-3cc9-4670-bc38-4b77ec9de40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1425
        }
      },
      "source": [
        "model.fit([X, B], Y, batch_size=24, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21503/21503 [==============================] - 1527s 71ms/step - loss: nan - acc: 0.9635 - box_acc: nan\n",
            "Epoch 2/5\n",
            "21503/21503 [==============================] - 1527s 71ms/step - loss: nan - acc: 0.9635 - box_acc: nan\n",
            "Epoch 3/5\n",
            "21503/21503 [==============================] - 1526s 71ms/step - loss: nan - acc: 0.9635 - box_acc: nan\n",
            "Epoch 4/5\n",
            "21503/21503 [==============================] - 1527s 71ms/step - loss: nan - acc: 0.9635 - box_acc: nan\n",
            "Epoch 5/5\n",
            " 6552/21503 [========>.....................] - ETA: 17:40 - loss: nan - acc: 0.9634 - box_acc: nan"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-069969ebb4f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-a6O2eKv9ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('b.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MYbHFdEv9lM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([X, B], Y, batch_size=24, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "013jUYsCv9n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('c.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvmVQ0Yywbv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([X, B], Y, batch_size=24, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18O3QsbWwbzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('d.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlDofokswb2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([X, B], Y, batch_size=24, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR6Z7LrYwb8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('e.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ET9nOZwcB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([X, B], Y, batch_size=24, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zKtNFlFweDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('f.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9EMihDSweJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit([X, B], Y, batch_size=24, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB1_2s5nwePP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('g.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQd2nCgOvQOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict([X[0:1],B[0:1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63eWp54uvQRf",
        "colab_type": "code",
        "outputId": "22379407-2488-4215-8c43-b47e9df1610d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81, 5, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un5Hu75fvQT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.reshape(pred, (81,5,25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jgnM37vQW3",
        "colab_type": "code",
        "outputId": "eddc0d04-60a8-48eb-a35e-121fe8831ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "pred[0,0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.08451013,  0.2048617 , -0.00422354,  0.15586264,  0.1001126 ,\n",
              "       -0.23986438, -0.5606198 , -0.4443024 , -0.5036565 , -0.5584354 ,\n",
              "       -0.46697223, -0.48348624, -0.47443008, -0.5083746 , -0.41776383,\n",
              "       -0.5107503 , -0.6150923 , -0.46910584, -0.5449882 , -0.61194736,\n",
              "       -0.44241887, -0.3955664 , -0.4504314 , -0.5423577 , -0.6041516 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwPl9xk4f9H5",
        "colab_type": "code",
        "outputId": "3c4ea1c8-ec58-4cb2-c2a6-06aea370d17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1289
        }
      },
      "source": [
        "model.fit([X, B], Y, batch_size=16, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "  336/21503 [..............................] - ETA: 29:35 - loss: nan - acc: 0.8534"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-d5bfb8a1dc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVD0Q05qkVXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}