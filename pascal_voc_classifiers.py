# -*- coding: utf-8 -*-
"""PASCAL VOC CLASSIFIERS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O0wjOQ3jUQBfjpRtWevQ-litV7AHtLwQ
"""

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

!mkdir -p drive
!google-drive-ocamlfuse drive

cd drive

ls

cd pascal_data

ls

import numpy as np

X = np.load('pascalX.npy')
Y = np.load('pascaly.npy')

print(X.shape)
print(Y.shape)

X_val = np.load('pascalX_val.npy')
Y_val = np.load('pascaly_val.npy')

import keras
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import six
from keras import backend as K
from keras.utils.generic_utils import deserialize_keras_object
from keras.utils.generic_utils import serialize_keras_object


def custom_error(y_true, y_pred):
    return K.mean(K.square(K.square(y_pred) - K.square(y_true)), axis=-1)

# import modules
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.layers.normalization import BatchNormalization
from keras import optimizers
import keras

"""#_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-"""

x = Sequential()

# Block 1
x.add(Conv2D(28, (3, 3),activation='relu',padding='same',input_shape=(300,300,3)))
x.add(Conv2D(28, (3, 3),activation='relu',padding='same'))
x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))

# Block 2
x.add(Conv2D(28, (3, 3),activation='relu',padding='same'))
x.add(Conv2D(28, (3, 3),activation='relu',padding='same',name='block2_conv2'))
x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))

# Block 3
x.add(Conv2D(28, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(64, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(64, (3, 3),activation='relu',padding='same'))

x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))

# Block 4
x.add(Conv2D(64, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(64, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(64, (3, 3),activation='relu',padding='same'))

x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))

# Block 5
x.add(Conv2D(128, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(128, (3, 3),activation='relu',padding='same'))

x.add(Dropout(0.2))
x.add(Conv2D(64, (3, 3),activation='relu',padding='same'))
x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))


# Classification block
x.add(Flatten())

x.add(Dense(1000, activation='relu'))
x.add(Dense(400, activation='relu'))
x.add(Dense(20, activation='softmax', name='predictions'))

sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)
#nadam = optimizers.Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)
x.compile(loss='mean_squared_error',
              optimizer=sgd,
              metrics=['accuracy'])

"""# Version 1"""

sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)
#nadam = optimizers.Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)
x.compile(loss='mean_squared_error',
              optimizer=sgd,
              metrics=['accuracy'])

for i in range(25):
  print("epoch",i)
  x.fit(X, Y,epochs=1,batch_size=20,validation_data=(X_val, Y_val))
  x.save('ePascalVOCClassifier.h5')
  print("----------------------------------------------------------------------")
  print("----------------------------------------------------------------------")

x.evaluate(X_val, Y_val)

"""#Version 1.1"""

"""
from keras.models import load_model
x = load_model('ePascalVOCClassifier.h5')
x.evaluate(x=X_val, y=Y_val)
"""

sgd = optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)
#nadam = optimizers.Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)
x.compile(loss='mean_squared_error',
              optimizer=sgd,
              metrics=['accuracy'])

for i in range(100):
  print("epoch",i)
  x.fit(X, Y,epochs=1,batch_size=20,validation_data=(X_val, Y_val))
  x.save('ePascalVOCClassifier_epoch18above.h5')
  print("----------------------------------------------------------------------")
  print("----------------------------------------------------------------------")

from keras.models import load_model
x = load_model('ePascalVOCClassifier_epoch18above.h5')

a = np.zeros((1,300,300,3))
a[0] = X_val[70]
pred = x.predict(a)
print(pred)













"""#Version 2"""

x = Sequential()

# Block 1
x.add(Conv2D(64, (3, 3),activation='relu',padding='same',input_shape=(300,300,3)))
x.add(Conv2D(64, (3, 3),activation='relu',padding='same'))
x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))

# Block 2
x.add(Conv2D(128, (3, 3),activation='relu',padding='same'))
x.add(Conv2D(128, (3, 3),activation='relu',padding='same',name='block2_conv2'))
x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))
x.add(BatchNormalization())

# Block 3
x.add(Conv2D(256, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(256, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(256, (3, 3),activation='relu',padding='same'))

x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))

# Block 4
x.add(Conv2D(512, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(512, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(512, (3, 3),activation='relu',padding='same'))

x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))

x.add(BatchNormalization())

# Block 5
x.add(Conv2D(512, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(512, (3, 3),activation='relu',padding='same'))

x.add(Conv2D(512, (3, 3),activation='relu',padding='same'))

x.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))
x.add(BatchNormalization())

# Classification block
x.add(Flatten())

x.add(Dense(1000, activation='relu'))
x.add(Dense(200, activation='relu'))
x.add(Dense(20, activation='softmax', name='predictions'))

# original parameters (lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)
sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)

# original parameters (lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)
nadam = optimizers.Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)

# original parameters (lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)

x.compile(loss='mean_squared_error',
              optimizer=adam,
              metrics=['accuracy'])



for i in range(25):
  print("epoch",i+1)
  x.fit(X, Y,epochs=1,batch_size=25,validation_data=(X_val, Y_val))
  x.save('ePascalVOCClassifier_epoch18aboveV_1_2.h5')
  print("----------------------------------------------------------------------")
  print("----------------------------------------------------------------------")

# Sunk Cost Fallacy





