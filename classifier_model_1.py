# -*- coding: utf-8 -*-
"""Classifier Model 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cM_nfi6WswnCmWLYvystX2AUnFGQiFd0
"""

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

!mkdir -p drive
!google-drive-ocamlfuse drive

ls

cd drive

ls

cd database

ls

import numpy as np

X = np.load('normalized_bath0.npy')
Y = np.load('Y_coco.npy')

print(X.shape)
print(Y.shape)

# import modules
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.layers.normalization import BatchNormalization
from keras import optimizers
import keras

model = Sequential()

model.add(Conv2D(64, (1, 1), input_shape=(300,300,3)))
model.add(BatchNormalization())
model.add(Activation('relu'))


model.add(Conv2D(64, (1, 1)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2), strides=1))


model.add(Conv2D(128,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Conv2D(128,(1, 1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=1))

model.add(Conv2D(128,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Conv2D(256,(1, 1)))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Conv2D(256,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=1))

model.add(Conv2D(512,(1, 1)))
model.add(BatchNormalization())
model.add(Activation('relu'))


model.add(Conv2D(512,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Conv2D(512,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=1))

model.add(Conv2D(512,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=1))


model.add(Conv2D(512,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=1))

model.add(Conv2D(512,(2, 2)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=1))


model.add(Flatten())
# Fully connected layer


model.add(Dense(2000))
model.add(Activation('relu'))
BatchNormalization()
model.add(Dropout(0.2))

model.add(Dense(500))
model.add(Activation('relu'))
BatchNormalization()
model.add(Dropout(0.2))


model.add(Dense(91))

model.add(Activation('softmax'))

sgd = optimizers.SGD(lr=0.01, clipvalue=0.5)
model.compile(loss='mean_squared_error',
              optimizer=sgd,
              metrics=['accuracy'])

model.fit(X, Y[0:10000],
          epochs=5,
          batch_size=20)

#score = model.evaluate(X_test, Y_test, batch_size=32)
print("--------------------------------------------")
print("Score is",score)

# save weights
#model.save_weights('keras_digit_classifier.h5')

!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi
!pip install gputil
!pip install psutil
!pip install humanize
import psutil
import humanize
import os
import GPUtil as GPU
GPUs = GPU.getGPUs()
# XXX: only one GPU on Colab and isnâ€™t guaranteed
gpu = GPUs[0]
def printm():
 process = psutil.Process(os.getpid())
 print("Gen RAM Free: " + humanize.naturalsize( psutil.virtual_memory().available ), " | Proc size: " + humanize.naturalsize( process.memory_info().rss))
 print("GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))
printm()







!kill-91

!kill -9 -1

